{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqBnGI1ltMfn"
   },
   "source": [
    "# **Mountain Car (Discrete case)**\n",
    "\n",
    "References :\n",
    "\n",
    "SARSA:  https://github.com/nicklasbekkevold/SARSA-mountaincar\n",
    "\n",
    "SARSA (lambda) : https://github.com/dariopavllo/mountaincar-sarsa-lambda\n",
    "\n",
    "Semi-Gradient SARSA : https://github.com/MikeS96/rl_openai/blob/master/Mountain%20Car.ipynb\n",
    "http://www.incompleteideas.net/book/RLbook2018.pdf#page=267\n",
    "\n",
    "\n",
    "PPO:    https://github.com/rossettisimone/PPO_MOUNTAINCAR_DISCRETE.\n",
    "\n",
    "Reddit: www.reddit.com/r/reinforcementlearning/comments/axp63j/d_state_of_the_art_deeprl_still_struggles_to/.  \n",
    "https://arxiv.org/pdf/1802.05054\n",
    "\n",
    "\n",
    "Documentation pour la librairie tiles3 : http://incompleteideas.net/tiles/tiles3.html\n",
    "\n",
    "\n",
    "Q-learning : https://www.kaggle.com/code/rezafazel63/mountain-car-is-a-classic-reinforcement-learning\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wl4ESb-y_rZ"
   },
   "source": [
    "# Google Colab configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62IGM72q6dRu",
    "outputId": "b11cc843-5fdf-466e-dbf4-acc44e723321"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "     - ----------------------------------- 20.5/721.7 kB 217.9 kB/s eta 0:00:04\n",
      "     -- ---------------------------------- 41.0/721.7 kB 393.8 kB/s eta 0:00:02\n",
      "     ---------------- --------------------- 317.4/721.7 kB 2.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ----- 614.4/721.7 kB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 721.7/721.7 kB 3.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting numpy>=1.18.0 (from gym)\n",
      "  Using cached numpy-2.2.0-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting cloudpickle>=1.2.0 (from gym)\n",
      "  Using cached cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting gym_notices>=0.0.4 (from gym)\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl.metadata (1.0 kB)\n",
      "Using cached cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Using cached numpy-2.2.0-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml): started\n",
      "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827635 sha256=c5e768eb74ed71f877e837ecb8062175c855bb8c2bf82a7efbab05d7061538dd\n",
      "  Stored in directory: c:\\users\\salma\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local\\pip\\cache\\wheels\\1c\\77\\9e\\9af5470201a0b0543937933ee99ba884cd237d2faefe8f4d37\n",
      "Successfully built gym\n",
      "Installing collected packages: gym_notices, numpy, cloudpickle, gym\n",
      "Successfully installed cloudpickle-3.1.0 gym-0.26.2 gym_notices-0.0.8 numpy-2.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[classic_control] in c:\\dev\\m2_iasd\\rl\\project\\mountain_car\\.venv\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\dev\\m2_iasd\\rl\\project\\mountain_car\\.venv\\lib\\site-packages (from gym[classic_control]) (2.2.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\dev\\m2_iasd\\rl\\project\\mountain_car\\.venv\\lib\\site-packages (from gym[classic_control]) (3.1.0)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in c:\\dev\\m2_iasd\\rl\\project\\mountain_car\\.venv\\lib\\site-packages (from gym[classic_control]) (0.0.8)\n",
      "Collecting pygame==2.1.0 (from gym[classic_control])\n",
      "  Downloading pygame-2.1.0.tar.gz (5.8 MB)\n",
      "     ---------------------------------------- 0.0/5.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/5.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/5.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.1/5.8 MB 573.4 kB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.4/5.8 MB 2.4 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 1.2/5.8 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 2.4/5.8 MB 8.8 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 3.9/5.8 MB 12.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 5.0/5.8 MB 14.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.8/5.8 MB 16.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.8/5.8 MB 14.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [95 lines of output]\n",
      "      \n",
      "      \n",
      "      WARNING, No \"Setup\" File Exists, Running \"buildconfig/config.py\"\n",
      "      Using WINDOWS configuration...\n",
      "      \n",
      "      Making dir :prebuilt_downloads:\n",
      "      Downloading... https://www.libsdl.org/release/SDL2-devel-2.0.16-VC.zip 13d952c333f3c2ebe9b7bc0075b4ad2f784e7584\n",
      "      Unzipping :prebuilt_downloads\\SDL2-devel-2.0.16-VC.zip:\n",
      "      Downloading... https://www.libsdl.org/projects/SDL_image/release/SDL2_image-devel-2.0.5-VC.zip 137f86474691f4e12e76e07d58d5920c8d844d5b\n",
      "      Unzipping :prebuilt_downloads\\SDL2_image-devel-2.0.5-VC.zip:\n",
      "      Downloading... https://www.libsdl.org/projects/SDL_ttf/release/SDL2_ttf-devel-2.0.15-VC.zip 1436df41ebc47ac36e02ec9bda5699e80ff9bd27\n",
      "      Unzipping :prebuilt_downloads\\SDL2_ttf-devel-2.0.15-VC.zip:\n",
      "      Downloading... https://www.libsdl.org/projects/SDL_mixer/release/SDL2_mixer-devel-2.0.4-VC.zip 9097148f4529cf19f805ccd007618dec280f0ecc\n",
      "      Unzipping :prebuilt_downloads\\SDL2_mixer-devel-2.0.4-VC.zip:\n",
      "      Downloading... https://www.pygame.org/ftp/jpegsr9d.zip ed10aa2b5a0fcfe74f8a6f7611aeb346b06a1f99\n",
      "      Unzipping :prebuilt_downloads\\jpegsr9d.zip:\n",
      "      Downloading... https://pygame.org/ftp/prebuilt-x64-pygame-1.9.2-20150922.zip 3a5af3427b3aa13a0aaf5c4cb08daaed341613ed\n",
      "      Unzipping :prebuilt_downloads\\prebuilt-x64-pygame-1.9.2-20150922.zip:\n",
      "      copying into .\\prebuilt-x64\n",
      "      Path for SDL: prebuilt-x64\\SDL2-2.0.16\n",
      "      ...Library directory for SDL: prebuilt-x64/SDL2-2.0.16/lib/x64\n",
      "      ...Include directory for SDL: prebuilt-x64/SDL2-2.0.16/include\n",
      "      Path for FONT: prebuilt-x64\\SDL2_ttf-2.0.15\n",
      "      ...Library directory for FONT: prebuilt-x64/SDL2_ttf-2.0.15/lib/x64\n",
      "      ...Include directory for FONT: prebuilt-x64/SDL2_ttf-2.0.15/include\n",
      "      Path for IMAGE: prebuilt-x64\\SDL2_image-2.0.5\n",
      "      ...Library directory for IMAGE: prebuilt-x64/SDL2_image-2.0.5/lib/x64\n",
      "      ...Include directory for IMAGE: prebuilt-x64/SDL2_image-2.0.5/include\n",
      "      Path for MIXER: prebuilt-x64\\SDL2_mixer-2.0.4\n",
      "      ...Library directory for MIXER: prebuilt-x64/SDL2_mixer-2.0.4/lib/x64\n",
      "      ...Include directory for MIXER: prebuilt-x64/SDL2_mixer-2.0.4/include\n",
      "      Path for PORTMIDI: prebuilt-x64\n",
      "      ...Library directory for PORTMIDI: prebuilt-x64/lib\n",
      "      ...Include directory for PORTMIDI: prebuilt-x64/include\n",
      "      DLL for SDL2: prebuilt-x64/SDL2-2.0.16/lib/x64/SDL2.dll\n",
      "      DLL for SDL2_ttf: prebuilt-x64/SDL2_ttf-2.0.15/lib/x64/SDL2_ttf.dll\n",
      "      DLL for SDL2_image: prebuilt-x64/SDL2_image-2.0.5/lib/x64/SDL2_image.dll\n",
      "      DLL for SDL2_mixer: prebuilt-x64/SDL2_mixer-2.0.4/lib/x64/SDL2_mixer.dll\n",
      "      DLL for portmidi: prebuilt-x64/lib/portmidi.dll\n",
      "      Path for FREETYPE not found.\n",
      "      ...Found include dir but no library dir in prebuilt-x64.\n",
      "      Path for PNG not found.\n",
      "      ...Found include dir but no library dir in prebuilt-x64.\n",
      "      Path for JPEG not found.\n",
      "      ...Found include dir but no library dir in prebuilt-x64.\n",
      "      DLL for freetype: prebuilt-x64/SDL2_ttf-2.0.15/lib/x64/libfreetype-6.dll\n",
      "      \n",
      "      ---\n",
      "      For help with compilation see:\n",
      "          https://www.pygame.org/wiki/CompileWindows\n",
      "      To contribute to pygame development see:\n",
      "          https://www.pygame.org/contribute.html\n",
      "      ---\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\salma\\AppData\\Local\\Temp\\pip-install-p5ufn4hx\\pygame_694e459e4d7f4962a9572a64388c3da2\\buildconfig\\config_win.py\", line 336, in configure\n",
      "          from . import vstools\n",
      "        File \"C:\\Users\\salma\\AppData\\Local\\Temp\\pip-install-p5ufn4hx\\pygame_694e459e4d7f4962a9572a64388c3da2\\buildconfig\\vstools.py\", line 5, in <module>\n",
      "          from distutils.msvccompiler import MSVCCompiler, get_build_architecture\n",
      "      ModuleNotFoundError: No module named 'distutils.msvccompiler'\n",
      "      \n",
      "      During handling of the above exception, another exception occurred:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\DEV\\M2_IASD\\RL\\Project\\mountain_car\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"C:\\DEV\\M2_IASD\\RL\\Project\\mountain_car\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\DEV\\M2_IASD\\RL\\Project\\mountain_car\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\salma\\AppData\\Local\\Temp\\pip-build-env-xzi3_lor\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 334, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=[])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\salma\\AppData\\Local\\Temp\\pip-build-env-xzi3_lor\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 304, in _get_build_requires\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\salma\\AppData\\Local\\Temp\\pip-build-env-xzi3_lor\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 522, in run_setup\n",
      "          super().run_setup(setup_script=setup_script)\n",
      "        File \"C:\\Users\\salma\\AppData\\Local\\Temp\\pip-build-env-xzi3_lor\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 320, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 388, in <module>\n",
      "        File \"C:\\Users\\salma\\AppData\\Local\\Temp\\pip-install-p5ufn4hx\\pygame_694e459e4d7f4962a9572a64388c3da2\\buildconfig\\config.py\", line 234, in main\n",
      "          deps = CFG.main(**kwds)\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\salma\\AppData\\Local\\Temp\\pip-install-p5ufn4hx\\pygame_694e459e4d7f4962a9572a64388c3da2\\buildconfig\\config_win.py\", line 511, in main\n",
      "          return setup_prebuilt_sdl2(prebuilt_dir)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\salma\\AppData\\Local\\Temp\\pip-install-p5ufn4hx\\pygame_694e459e4d7f4962a9572a64388c3da2\\buildconfig\\config_win.py\", line 471, in setup_prebuilt_sdl2\n",
      "          DEPS.configure()\n",
      "        File \"C:\\Users\\salma\\AppData\\Local\\Temp\\pip-install-p5ufn4hx\\pygame_694e459e4d7f4962a9572a64388c3da2\\buildconfig\\config_win.py\", line 338, in configure\n",
      "          from buildconfig import vstools\n",
      "        File \"C:\\Users\\salma\\AppData\\Local\\Temp\\pip-install-p5ufn4hx\\pygame_694e459e4d7f4962a9572a64388c3da2\\buildconfig\\vstools.py\", line 5, in <module>\n",
      "          from distutils.msvccompiler import MSVCCompiler, get_build_architecture\n",
      "      ModuleNotFoundError: No module named 'distutils.msvccompiler'\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyvirtualdisplay\n",
      "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: pyvirtualdisplay\n",
      "Successfully installed pyvirtualdisplay-3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gym\n",
    "!pip install gym[classic_control]\n",
    "!pip install pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0x99ZxXShKq"
   },
   "outputs": [],
   "source": [
    "# !pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
    "# !apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
    "# !apt-get update > /dev/null 2>&1\n",
    "# !apt-get install cmake > /dev/null 2>&1\n",
    "# !pip install --upgrade setuptools 2>&1\n",
    "# !pip install ez_setup > /dev/null 2>&1\n",
    "# !apt-get install -y xvfb\n",
    "\n",
    "\n",
    "def wrap_env(env):\n",
    "    env = RecordVideo(env, \"./video\")\n",
    "    return env\n",
    "\n",
    "\n",
    "def show_video():\n",
    "    mp4list = glob.glob(\"video/*.mp4\")\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, \"r+b\").read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(\n",
    "            HTML(\n",
    "                data=\"\"\"<video alt=\"test\" autoplay\n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>\"\"\".format(\n",
    "                    encoded.decode(\"ascii\")\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        print(\"Could not find video\")\n",
    "\n",
    "\n",
    "# A executer avant l'initialisation de env\n",
    "# display = Display(visible=0, size=(1400, 900))\n",
    "# display.start()\n",
    "# env = wrap_env(gym.make('MountainCar-v0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-CUN_-zF4ZI"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YznFMOFRzE0M"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "# from gym.wrappers.record_video import RecordVideo\n",
    "# import glob\n",
    "# import io\n",
    "# import base64\n",
    "# from IPython.display import HTML\n",
    "# from pyvirtualdisplay import Display\n",
    "# from IPython import display as ipythondisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yZDd5xPGfhB"
   },
   "source": [
    "# 1. Functions & Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sNaqXF6GlnZ"
   },
   "source": [
    "## 1.1. Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "R_zyyJHF85pZ"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "class IHT:\n",
    "    def __init__(self, sizeval):\n",
    "        self.size = sizeval\n",
    "        self.overfullCount = 0\n",
    "        self.dictionary = {}\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\n",
    "            \"Collision table: size: \"\n",
    "            + str(self.size)\n",
    "            + \" overfullCount: \"\n",
    "            + str(self.overfullCount)\n",
    "            + \" dictionary: \"\n",
    "            + str(len(self.dictionary))\n",
    "        )\n",
    "\n",
    "    def count(self):\n",
    "        return len(self.dictionary)\n",
    "\n",
    "    def fullp(self):\n",
    "        return len(self.dictionary) >= self.size\n",
    "\n",
    "    def getindex(self, obj, readonly=False):\n",
    "        if obj in self.dictionary:\n",
    "            return self.dictionary[obj]\n",
    "        elif readonly:\n",
    "            return None\n",
    "        size = self.size\n",
    "        if len(self.dictionary) >= size:\n",
    "            if self.overfullCount == 0:\n",
    "                print(\"IHT full, starting to allow collisions\")\n",
    "            self.overfullCount += 1\n",
    "            return hash(obj) % self.size\n",
    "        else:\n",
    "            self.dictionary[obj] = len(self.dictionary)\n",
    "            return self.dictionary[obj]\n",
    "\n",
    "\n",
    "def hashcoords(coordinates, m, readonly=False):\n",
    "    if isinstance(m, IHT):\n",
    "        return m.getindex(tuple(coordinates), readonly)\n",
    "    if isinstance(m, int):\n",
    "        return hash(tuple(coordinates)) % m\n",
    "    if m is None:\n",
    "        return coordinates\n",
    "\n",
    "\n",
    "def get_tiles(ihtORsize, numtilings, floats, ints=[], readonly=False):\n",
    "    qfloats = [int(math.floor(f * numtilings)) for f in floats]\n",
    "    tiles = []\n",
    "    for tiling in range(numtilings):\n",
    "        tilingX2 = tiling * 2\n",
    "        coords = [tiling]\n",
    "        b = tiling\n",
    "        for q in qfloats:\n",
    "            coords.append((q + b) // numtilings)\n",
    "            b += tilingX2\n",
    "        coords.extend(ints)\n",
    "        tiles.append(hashcoords(coords, ihtORsize, readonly))\n",
    "    return tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5OJBYeuGoAh",
    "outputId": "8a1bd1aa-0256-4f23-ef35-a168fbed4ebb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiles activées : [0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "POSITION_MIN = -1.2\n",
    "POSITION_MAX = 0.5\n",
    "VELOCITY_MIN = -0.07\n",
    "VELOCITY_MAX = 0.07\n",
    "\n",
    "iht_size = 2024\n",
    "num_tilings = 8\n",
    "num_tiles = 8\n",
    "\n",
    "iht = IHT(2024)\n",
    "\n",
    "\n",
    "def mc_tile_encoding(state):\n",
    "    \"\"\"\n",
    "    Tile encoding function for states in mountain car gymnasium problem\n",
    "\n",
    "    Args:\n",
    "        - state (tuple): (position, velocity)\n",
    "\n",
    "    Returns:\n",
    "        - The list of the tiles corresponding to the given state\n",
    "    \"\"\"\n",
    "    # Extract the position and velocity from the gymnasium state\n",
    "    position, velocity = state\n",
    "\n",
    "    # Scale position and velocity by multiplying the inputs of each by their scale\n",
    "    position_scale = num_tiles / (POSITION_MAX - POSITION_MIN)\n",
    "    velocity_scale = num_tiles / (VELOCITY_MAX - VELOCITY_MIN)\n",
    "\n",
    "    # Obtain active tiles for current position and velocity\n",
    "    tiles = get_tiles(\n",
    "        iht, num_tilings, [position * position_scale, velocity * velocity_scale]\n",
    "    )\n",
    "\n",
    "    return np.array(tiles)\n",
    "\n",
    "\n",
    "print(\"Tiles activées :\", mc_tile_encoding((-1.0, 0.01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WDQitRjLG1N"
   },
   "source": [
    "## 1.2. Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftsyzYskVxNH"
   },
   "outputs": [],
   "source": [
    "def draw(policy, state_index):\n",
    "    \"\"\"\n",
    "    Draw an action for a given state by following the distribution of action probabilities of this state.\n",
    "\n",
    "    Args:\n",
    "      - policy (numpy.array): the policy i.e. the mapping (states: actions)\n",
    "      - state (int): the index of the state\n",
    "\n",
    "    Returns:\n",
    "      action (int): the number / index of the action for the given state index\n",
    "    \"\"\"\n",
    "\n",
    "    return np.random.choice(a=policy[state_index].shape[0], p=policy[state_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGCiJnKY-CN3"
   },
   "source": [
    "### SARSA Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "YLQWW3Kp-EA3"
   },
   "outputs": [],
   "source": [
    "# SARSA : Apprentissage on-policy avec mise à jour incrémentale des Q-valeurs.\n",
    "\n",
    "# alpha : Taux d’apprentissage.\n",
    "# gamma : Facteur de discount.\n",
    "# epsilon : Paramètre d’exploration.\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "def sarsa_mountain_car(episodes=500, alpha=0.1, gamma=0.99, epsilon=0.1):\n",
    "    \n",
    "    def get_Q_value(Q, state_tiles, action):\n",
    "        \"\"\"\n",
    "        For one state, summing on every values of corresponding tiles, with default = 0 if no value.\n",
    "        \"\"\"\n",
    "        return sum(Q.get((tile, action), 0) for tile in state_tiles)\n",
    "\n",
    "    def choose_action(Q, state_tiles, epsilon):\n",
    "        if np.random.rand() < epsilon:\n",
    "            return np.random.choice(num_actions)  # Exploration\n",
    "        else:\n",
    "            # Exploitation: Choose action with maximum Q-value\n",
    "            q_values = [get_Q_value(Q, state_tiles, a) for a in range(num_actions)]\n",
    "            return np.argmax(q_values)\n",
    "    \n",
    "    # Initialize Q-values (dictionary with default value 0)\n",
    "    Q = {}\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        position, velocity = state[0]\n",
    "        state_tiles = mc_tile_encoding(position, velocity)\n",
    "        action = choose_action(Q, state_tiles, epsilon)\n",
    "\n",
    "        done, time_over = False, False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not (done or time_over):\n",
    "            next_state, reward, done, time_over, _ = env.step(action)\n",
    "            next_position, next_velocity = next_state\n",
    "            next_state_tiles = mc_tile_encoding(next_position, next_velocity)\n",
    "            next_action = choose_action(Q, next_state_tiles, epsilon)\n",
    "\n",
    "            # Compute the SARSA update\n",
    "            q_current = get_Q_value(Q, state_tiles, action)\n",
    "            q_next = get_Q_value(Q, next_state_tiles, next_action) if not done else 0\n",
    "            target = reward + gamma * q_next\n",
    "            error = target - q_current\n",
    "\n",
    "            # Update Q-values for all tiles\n",
    "            for tile in state_tiles:\n",
    "                Q[(tile, action)] = Q.get((tile, action), 0) + alpha * error\n",
    "\n",
    "            # Move to the next state and action\n",
    "            state_tiles = next_state_tiles\n",
    "            action = next_action\n",
    "            total_reward += reward\n",
    "\n",
    "        print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarsaAgent:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env,\n",
    "        encode_fct,\n",
    "        nb_actions=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        - env (gymnasium.Env): The environment to train on.\n",
    "        - nb_actions (int): Number of possible actions.\n",
    "        - encode_fct (callable): Function to encode the state into features (e.g., tile coding).\n",
    "        \"\"\"\n",
    "        self.env = env\n",
    "        self.nb_actions = env.action_space.n if nb_actions == None else nb_actions\n",
    "        self.encode_fct = encode_fct\n",
    "        q = {}\n",
    "\n",
    "    def init(self):\n",
    "        \"\"\"Initialize q values\"\"\"\n",
    "        self.q = {}\n",
    "\n",
    "    def get_q_value(self, q, state, action):\n",
    "        \"\"\"Compute Q-value for a state-action pair by summing over the tiles.\"\"\"\n",
    "        return sum(q.get((tile, action), 0) for tile in self.encode_fct(state))\n",
    "\n",
    "    def choose_action(self, q, state, epsilon):\n",
    "        \"\"\"Choose an action using an epsilon-greedy policy.\"\"\"\n",
    "        if np.random.rand() < epsilon:\n",
    "            return np.random.choice(self.nb_actions)  # Exploration\n",
    "        else:\n",
    "            # Exploitation: Select the action with the highest Q-value\n",
    "            q_values = [self.get_q_value(q, state, a) for a in range(self.nb_actions)]\n",
    "            return np.argmax(q_values)\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        nb_episodes,\n",
    "        alpha=0.1,\n",
    "        gamma=0.99,\n",
    "        epsilon=0.1,\n",
    "        use_glei=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        SARSA algorithm for on-policy reinforcement learning.\n",
    "\n",
    "        Args:\n",
    "            - nb_episodes (int): Number of episodes to train for.\n",
    "            - alpha (float): Learning rate for updating Q-values.\n",
    "            - gamma (float): Discount factor for future rewards.\n",
    "            - epsilon (float): Initial exploration rate for epsilon-greedy policy.\n",
    "            - use_glei (bool): Whether to use a decaying epsilon (GLEI policy).\n",
    "            - decay_rate (float): Decay rate for epsilon in GLEI policy.\n",
    "            - min_epsilon (float): Minimum epsilon value in GLEI policy.\n",
    "\n",
    "        Returns:\n",
    "            - rewards_historic (list): History of rewards across episodes.\n",
    "        \"\"\"\n",
    "        rewads_historic = []\n",
    "        self.init()\n",
    "\n",
    "        for episode in range(nb_episodes):\n",
    "            state, _ = self.env.reset()\n",
    "            action = self.choose_action(self.q, state, epsilon)\n",
    "\n",
    "            task_completed, episode_over = False, False\n",
    "            total_reward = 0\n",
    "\n",
    "            while not (task_completed or episode_over):\n",
    "                next_state, reward, task_completed, episode_over, _ = self.env.step(\n",
    "                    action\n",
    "                )\n",
    "                next_action = self.choose_action(self.q, next_state, epsilon)\n",
    "\n",
    "                # Compute the SARSA update\n",
    "                q_current = self.get_q_value(self.q, state, action)\n",
    "                q_next = (\n",
    "                    self.get_q_value(self.q, next_state, next_action)\n",
    "                    if not (task_completed or episode_over)\n",
    "                    else 0\n",
    "                )\n",
    "                target = reward + gamma * q_next\n",
    "                error = target - q_current\n",
    "\n",
    "                # Update Q-values for all tiles\n",
    "                for tile in self.encode_fct(state):\n",
    "                    self.q[(tile, action)] = (\n",
    "                        self.q.get((tile, action), 0) + alpha * error\n",
    "                    )\n",
    "\n",
    "                # Move to the next state and action\n",
    "                state = next_state\n",
    "                action = next_action\n",
    "                total_reward += reward\n",
    "\n",
    "            rewads_historic.append(total_reward)\n",
    "            print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "        return rewads_historic\n",
    "\n",
    "    def evaluate_agent(self, nb_trainings, nb_episodes):\n",
    "        \"\"\"\n",
    "        Train the agent multiple times in order to evaluate its training parameters with mean and standard deviation over episodes\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa(\n",
    "    env,\n",
    "    nb_actions,\n",
    "    encode_fct,\n",
    "    nb_episodes=500,\n",
    "    alpha=0.1,\n",
    "    gamma=0.99,\n",
    "    epsilon=0.1,\n",
    "    use_glei=False,\n",
    "    decay_rate=0.2,\n",
    "    min_epsilon=0.05,\n",
    "):\n",
    "    \"\"\"\n",
    "    SARSA algorithm for on-policy reinforcement learning.\n",
    "\n",
    "    Args:\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        - q (dict): The Q-values represented as a dictionary.\n",
    "        - rewards_historic (list): History of rewards across episodes.\n",
    "    \"\"\"\n",
    "    # Initialize Q-values as a dictionary with default value 0\n",
    "    q = {}\n",
    "    rewards_historic = []\n",
    "    count_decay = 1\n",
    "\n",
    "    for episode in range(nb_episodes):\n",
    "        # Initialize environment and encode initial state\n",
    "        state = env.reset()[0]\n",
    "        state_tiles = encode_fct(state)\n",
    "        action = choose_action_sarsa(q, state_tiles, nb_actions, epsilon)\n",
    "\n",
    "        total_reward = 0\n",
    "        terminated = False\n",
    "\n",
    "        while not terminated:\n",
    "            # Take a step in the environment\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "            # Encode the next state and choose the next action\n",
    "            next_state_tiles = encode_fct(*next_state)\n",
    "            next_action = choose_action_sarsa(q, next_state_tiles, nb_actions, epsilon)\n",
    "\n",
    "            # SARSA Q-value update\n",
    "            q_current = get_q_value_sarsa(q, state_tiles, action)\n",
    "            q_next = (\n",
    "                get_q_value_sarsa(q, next_state_tiles, next_action)\n",
    "                if not terminated\n",
    "                else 0\n",
    "            )\n",
    "            q_target = reward + gamma * q_next\n",
    "            error = q_target - q_current\n",
    "\n",
    "            # Update Q-values for all tiles in the state representation\n",
    "            for tile in state_tiles:\n",
    "                q[(tile, action)] = q.get((tile, action), 0) + alpha * error\n",
    "\n",
    "            # Move to the next state and action\n",
    "            state_tiles = next_state_tiles\n",
    "            action = next_action\n",
    "\n",
    "        # Track total reward for the episode\n",
    "        rewards_historic.append(total_reward)\n",
    "\n",
    "        # Decay epsilon if GLEI policy is enabled\n",
    "        if use_glei and episode > decay_rate * count_decay * nb_episodes:\n",
    "            epsilon = max(epsilon * (1 - decay_rate * count_decay), min_epsilon)\n",
    "            count_decay += 1\n",
    "\n",
    "        print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "    return q, rewards_historic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BnhOzsn9_QqC",
    "outputId": "7e37daa9-ffb8-4b33-c66d-7517c4ab202d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -200.0\n",
      "Episode 2: Total Reward = -200.0\n",
      "Episode 3: Total Reward = -200.0\n",
      "Episode 4: Total Reward = -200.0\n",
      "Episode 5: Total Reward = -200.0\n",
      "Episode 6: Total Reward = -200.0\n",
      "Episode 7: Total Reward = -200.0\n",
      "Episode 8: Total Reward = -200.0\n",
      "Episode 9: Total Reward = -200.0\n",
      "Episode 10: Total Reward = -200.0\n",
      "Episode 11: Total Reward = -200.0\n",
      "Episode 12: Total Reward = -200.0\n",
      "Episode 13: Total Reward = -200.0\n",
      "Episode 14: Total Reward = -200.0\n",
      "Episode 15: Total Reward = -200.0\n",
      "Episode 16: Total Reward = -200.0\n",
      "Episode 17: Total Reward = -200.0\n",
      "Episode 18: Total Reward = -200.0\n",
      "Episode 19: Total Reward = -200.0\n",
      "Episode 20: Total Reward = -200.0\n",
      "Episode 21: Total Reward = -185.0\n",
      "Episode 22: Total Reward = -200.0\n",
      "Episode 23: Total Reward = -155.0\n",
      "Episode 24: Total Reward = -200.0\n",
      "Episode 25: Total Reward = -200.0\n",
      "Episode 26: Total Reward = -162.0\n",
      "Episode 27: Total Reward = -167.0\n",
      "Episode 28: Total Reward = -164.0\n",
      "Episode 29: Total Reward = -200.0\n",
      "Episode 30: Total Reward = -157.0\n",
      "Episode 31: Total Reward = -183.0\n",
      "Episode 32: Total Reward = -200.0\n",
      "Episode 33: Total Reward = -193.0\n",
      "Episode 34: Total Reward = -179.0\n",
      "Episode 35: Total Reward = -159.0\n",
      "Episode 36: Total Reward = -153.0\n",
      "Episode 37: Total Reward = -189.0\n",
      "Episode 38: Total Reward = -195.0\n",
      "Episode 39: Total Reward = -200.0\n",
      "Episode 40: Total Reward = -160.0\n",
      "Episode 41: Total Reward = -200.0\n",
      "Episode 42: Total Reward = -200.0\n",
      "Episode 43: Total Reward = -153.0\n",
      "Episode 44: Total Reward = -149.0\n",
      "Episode 45: Total Reward = -200.0\n",
      "Episode 46: Total Reward = -159.0\n",
      "Episode 47: Total Reward = -161.0\n",
      "Episode 48: Total Reward = -200.0\n",
      "Episode 49: Total Reward = -200.0\n",
      "Episode 50: Total Reward = -180.0\n",
      "Episode 51: Total Reward = -160.0\n",
      "Episode 52: Total Reward = -200.0\n",
      "Episode 53: Total Reward = -153.0\n",
      "Episode 54: Total Reward = -153.0\n",
      "Episode 55: Total Reward = -154.0\n",
      "Episode 56: Total Reward = -152.0\n",
      "Episode 57: Total Reward = -117.0\n",
      "Episode 58: Total Reward = -200.0\n",
      "Episode 59: Total Reward = -147.0\n",
      "Episode 60: Total Reward = -190.0\n",
      "Episode 61: Total Reward = -189.0\n",
      "Episode 62: Total Reward = -117.0\n",
      "Episode 63: Total Reward = -170.0\n",
      "Episode 64: Total Reward = -200.0\n",
      "Episode 65: Total Reward = -155.0\n",
      "Episode 66: Total Reward = -116.0\n",
      "Episode 67: Total Reward = -148.0\n",
      "Episode 68: Total Reward = -147.0\n",
      "Episode 69: Total Reward = -116.0\n",
      "Episode 70: Total Reward = -146.0\n",
      "Episode 71: Total Reward = -139.0\n",
      "Episode 72: Total Reward = -164.0\n",
      "Episode 73: Total Reward = -154.0\n",
      "Episode 74: Total Reward = -117.0\n",
      "Episode 75: Total Reward = -170.0\n",
      "Episode 76: Total Reward = -147.0\n",
      "Episode 77: Total Reward = -152.0\n",
      "Episode 78: Total Reward = -145.0\n",
      "Episode 79: Total Reward = -149.0\n",
      "Episode 80: Total Reward = -145.0\n",
      "Episode 81: Total Reward = -115.0\n",
      "Episode 82: Total Reward = -154.0\n",
      "Episode 83: Total Reward = -155.0\n",
      "Episode 84: Total Reward = -150.0\n",
      "Episode 85: Total Reward = -157.0\n",
      "Episode 86: Total Reward = -155.0\n",
      "Episode 87: Total Reward = -189.0\n",
      "Episode 88: Total Reward = -126.0\n",
      "Episode 89: Total Reward = -149.0\n",
      "Episode 90: Total Reward = -200.0\n",
      "Episode 91: Total Reward = -162.0\n",
      "Episode 92: Total Reward = -168.0\n",
      "Episode 93: Total Reward = -158.0\n",
      "Episode 94: Total Reward = -154.0\n",
      "Episode 95: Total Reward = -116.0\n",
      "Episode 96: Total Reward = -152.0\n",
      "Episode 97: Total Reward = -154.0\n",
      "Episode 98: Total Reward = -117.0\n",
      "Episode 99: Total Reward = -151.0\n",
      "Episode 100: Total Reward = -151.0\n",
      "Episode 101: Total Reward = -155.0\n",
      "Episode 102: Total Reward = -163.0\n",
      "Episode 103: Total Reward = -119.0\n",
      "Episode 104: Total Reward = -129.0\n",
      "Episode 105: Total Reward = -96.0\n",
      "Episode 106: Total Reward = -91.0\n",
      "Episode 107: Total Reward = -113.0\n",
      "Episode 108: Total Reward = -117.0\n",
      "Episode 109: Total Reward = -130.0\n",
      "Episode 110: Total Reward = -155.0\n",
      "Episode 111: Total Reward = -119.0\n",
      "Episode 112: Total Reward = -149.0\n",
      "Episode 113: Total Reward = -159.0\n",
      "Episode 114: Total Reward = -151.0\n",
      "Episode 115: Total Reward = -144.0\n",
      "Episode 116: Total Reward = -153.0\n",
      "Episode 117: Total Reward = -150.0\n",
      "Episode 118: Total Reward = -197.0\n",
      "Episode 119: Total Reward = -144.0\n",
      "Episode 120: Total Reward = -149.0\n",
      "Episode 121: Total Reward = -140.0\n",
      "Episode 122: Total Reward = -182.0\n",
      "Episode 123: Total Reward = -139.0\n",
      "Episode 124: Total Reward = -151.0\n",
      "Episode 125: Total Reward = -150.0\n",
      "Episode 126: Total Reward = -153.0\n",
      "Episode 127: Total Reward = -156.0\n",
      "Episode 128: Total Reward = -154.0\n",
      "Episode 129: Total Reward = -157.0\n",
      "Episode 130: Total Reward = -153.0\n",
      "Episode 131: Total Reward = -191.0\n",
      "Episode 132: Total Reward = -156.0\n",
      "Episode 133: Total Reward = -110.0\n",
      "Episode 134: Total Reward = -153.0\n",
      "Episode 135: Total Reward = -151.0\n",
      "Episode 136: Total Reward = -149.0\n",
      "Episode 137: Total Reward = -135.0\n",
      "Episode 138: Total Reward = -137.0\n",
      "Episode 139: Total Reward = -112.0\n",
      "Episode 140: Total Reward = -108.0\n",
      "Episode 141: Total Reward = -114.0\n",
      "Episode 142: Total Reward = -139.0\n",
      "Episode 143: Total Reward = -157.0\n",
      "Episode 144: Total Reward = -156.0\n",
      "Episode 145: Total Reward = -146.0\n",
      "Episode 146: Total Reward = -112.0\n",
      "Episode 147: Total Reward = -144.0\n",
      "Episode 148: Total Reward = -149.0\n",
      "Episode 149: Total Reward = -151.0\n",
      "Episode 150: Total Reward = -152.0\n",
      "Episode 151: Total Reward = -159.0\n",
      "Episode 152: Total Reward = -112.0\n",
      "Episode 153: Total Reward = -182.0\n",
      "Episode 154: Total Reward = -167.0\n",
      "Episode 155: Total Reward = -149.0\n",
      "Episode 156: Total Reward = -145.0\n",
      "Episode 157: Total Reward = -149.0\n",
      "Episode 158: Total Reward = -144.0\n",
      "Episode 159: Total Reward = -145.0\n",
      "Episode 160: Total Reward = -138.0\n",
      "Episode 161: Total Reward = -138.0\n",
      "Episode 162: Total Reward = -150.0\n",
      "Episode 163: Total Reward = -119.0\n",
      "Episode 164: Total Reward = -172.0\n",
      "Episode 165: Total Reward = -140.0\n",
      "Episode 166: Total Reward = -141.0\n",
      "Episode 167: Total Reward = -144.0\n",
      "Episode 168: Total Reward = -139.0\n",
      "Episode 169: Total Reward = -144.0\n",
      "Episode 170: Total Reward = -183.0\n",
      "Episode 171: Total Reward = -148.0\n",
      "Episode 172: Total Reward = -156.0\n",
      "Episode 173: Total Reward = -147.0\n",
      "Episode 174: Total Reward = -185.0\n",
      "Episode 175: Total Reward = -148.0\n",
      "Episode 176: Total Reward = -151.0\n",
      "Episode 177: Total Reward = -150.0\n",
      "Episode 178: Total Reward = -141.0\n",
      "Episode 179: Total Reward = -148.0\n",
      "Episode 180: Total Reward = -154.0\n",
      "Episode 181: Total Reward = -110.0\n",
      "Episode 182: Total Reward = -113.0\n",
      "Episode 183: Total Reward = -183.0\n",
      "Episode 184: Total Reward = -159.0\n",
      "Episode 185: Total Reward = -156.0\n",
      "Episode 186: Total Reward = -183.0\n",
      "Episode 187: Total Reward = -150.0\n",
      "Episode 188: Total Reward = -188.0\n",
      "Episode 189: Total Reward = -148.0\n",
      "Episode 190: Total Reward = -143.0\n",
      "Episode 191: Total Reward = -128.0\n",
      "Episode 192: Total Reward = -110.0\n",
      "Episode 193: Total Reward = -117.0\n",
      "Episode 194: Total Reward = -110.0\n",
      "Episode 195: Total Reward = -150.0\n",
      "Episode 196: Total Reward = -88.0\n",
      "Episode 197: Total Reward = -111.0\n",
      "Episode 198: Total Reward = -154.0\n",
      "Episode 199: Total Reward = -145.0\n",
      "Episode 200: Total Reward = -95.0\n",
      "Episode 201: Total Reward = -147.0\n",
      "Episode 202: Total Reward = -147.0\n",
      "Episode 203: Total Reward = -139.0\n",
      "Episode 204: Total Reward = -122.0\n",
      "Episode 205: Total Reward = -149.0\n",
      "Episode 206: Total Reward = -153.0\n",
      "Episode 207: Total Reward = -151.0\n",
      "Episode 208: Total Reward = -155.0\n",
      "Episode 209: Total Reward = -151.0\n",
      "Episode 210: Total Reward = -148.0\n",
      "Episode 211: Total Reward = -151.0\n",
      "Episode 212: Total Reward = -142.0\n",
      "Episode 213: Total Reward = -115.0\n",
      "Episode 214: Total Reward = -161.0\n",
      "Episode 215: Total Reward = -110.0\n",
      "Episode 216: Total Reward = -112.0\n",
      "Episode 217: Total Reward = -107.0\n",
      "Episode 218: Total Reward = -107.0\n",
      "Episode 219: Total Reward = -110.0\n",
      "Episode 220: Total Reward = -182.0\n",
      "Episode 221: Total Reward = -106.0\n",
      "Episode 222: Total Reward = -91.0\n",
      "Episode 223: Total Reward = -117.0\n",
      "Episode 224: Total Reward = -85.0\n",
      "Episode 225: Total Reward = -90.0\n",
      "Episode 226: Total Reward = -87.0\n",
      "Episode 227: Total Reward = -90.0\n",
      "Episode 228: Total Reward = -147.0\n",
      "Episode 229: Total Reward = -121.0\n",
      "Episode 230: Total Reward = -87.0\n",
      "Episode 231: Total Reward = -86.0\n",
      "Episode 232: Total Reward = -105.0\n",
      "Episode 233: Total Reward = -105.0\n",
      "Episode 234: Total Reward = -106.0\n",
      "Episode 235: Total Reward = -109.0\n",
      "Episode 236: Total Reward = -86.0\n",
      "Episode 237: Total Reward = -145.0\n",
      "Episode 238: Total Reward = -152.0\n",
      "Episode 239: Total Reward = -140.0\n",
      "Episode 240: Total Reward = -148.0\n",
      "Episode 241: Total Reward = -145.0\n",
      "Episode 242: Total Reward = -146.0\n",
      "Episode 243: Total Reward = -112.0\n",
      "Episode 244: Total Reward = -107.0\n",
      "Episode 245: Total Reward = -111.0\n",
      "Episode 246: Total Reward = -172.0\n",
      "Episode 247: Total Reward = -150.0\n",
      "Episode 248: Total Reward = -145.0\n",
      "Episode 249: Total Reward = -170.0\n",
      "Episode 250: Total Reward = -137.0\n",
      "Episode 251: Total Reward = -143.0\n",
      "Episode 252: Total Reward = -194.0\n",
      "Episode 253: Total Reward = -196.0\n",
      "Episode 254: Total Reward = -148.0\n",
      "Episode 255: Total Reward = -139.0\n",
      "Episode 256: Total Reward = -142.0\n",
      "Episode 257: Total Reward = -143.0\n",
      "Episode 258: Total Reward = -145.0\n",
      "Episode 259: Total Reward = -98.0\n",
      "Episode 260: Total Reward = -93.0\n",
      "Episode 261: Total Reward = -151.0\n",
      "Episode 262: Total Reward = -96.0\n",
      "Episode 263: Total Reward = -140.0\n",
      "Episode 264: Total Reward = -90.0\n",
      "Episode 265: Total Reward = -84.0\n",
      "Episode 266: Total Reward = -139.0\n",
      "Episode 267: Total Reward = -141.0\n",
      "Episode 268: Total Reward = -91.0\n",
      "Episode 269: Total Reward = -106.0\n",
      "Episode 270: Total Reward = -87.0\n",
      "Episode 271: Total Reward = -96.0\n",
      "Episode 272: Total Reward = -147.0\n",
      "Episode 273: Total Reward = -144.0\n",
      "Episode 274: Total Reward = -106.0\n",
      "Episode 275: Total Reward = -147.0\n",
      "Episode 276: Total Reward = -108.0\n",
      "Episode 277: Total Reward = -93.0\n",
      "Episode 278: Total Reward = -146.0\n",
      "Episode 279: Total Reward = -108.0\n",
      "Episode 280: Total Reward = -106.0\n",
      "Episode 281: Total Reward = -105.0\n",
      "Episode 282: Total Reward = -107.0\n",
      "Episode 283: Total Reward = -108.0\n",
      "Episode 284: Total Reward = -108.0\n",
      "Episode 285: Total Reward = -96.0\n",
      "Episode 286: Total Reward = -93.0\n",
      "Episode 287: Total Reward = -146.0\n",
      "Episode 288: Total Reward = -86.0\n",
      "Episode 289: Total Reward = -159.0\n",
      "Episode 290: Total Reward = -150.0\n",
      "Episode 291: Total Reward = -148.0\n",
      "Episode 292: Total Reward = -87.0\n",
      "Episode 293: Total Reward = -92.0\n",
      "Episode 294: Total Reward = -109.0\n",
      "Episode 295: Total Reward = -136.0\n",
      "Episode 296: Total Reward = -149.0\n",
      "Episode 297: Total Reward = -169.0\n",
      "Episode 298: Total Reward = -87.0\n",
      "Episode 299: Total Reward = -139.0\n",
      "Episode 300: Total Reward = -91.0\n",
      "Episode 301: Total Reward = -104.0\n",
      "Episode 302: Total Reward = -162.0\n",
      "Episode 303: Total Reward = -88.0\n",
      "Episode 304: Total Reward = -158.0\n",
      "Episode 305: Total Reward = -146.0\n",
      "Episode 306: Total Reward = -138.0\n",
      "Episode 307: Total Reward = -148.0\n",
      "Episode 308: Total Reward = -136.0\n",
      "Episode 309: Total Reward = -144.0\n",
      "Episode 310: Total Reward = -178.0\n",
      "Episode 311: Total Reward = -152.0\n",
      "Episode 312: Total Reward = -194.0\n",
      "Episode 313: Total Reward = -101.0\n",
      "Episode 314: Total Reward = -163.0\n",
      "Episode 315: Total Reward = -136.0\n",
      "Episode 316: Total Reward = -173.0\n",
      "Episode 317: Total Reward = -200.0\n",
      "Episode 318: Total Reward = -128.0\n",
      "Episode 319: Total Reward = -138.0\n",
      "Episode 320: Total Reward = -138.0\n",
      "Episode 321: Total Reward = -94.0\n",
      "Episode 322: Total Reward = -133.0\n",
      "Episode 323: Total Reward = -90.0\n",
      "Episode 324: Total Reward = -99.0\n",
      "Episode 325: Total Reward = -149.0\n",
      "Episode 326: Total Reward = -95.0\n",
      "Episode 327: Total Reward = -134.0\n",
      "Episode 328: Total Reward = -159.0\n",
      "Episode 329: Total Reward = -88.0\n",
      "Episode 330: Total Reward = -93.0\n",
      "Episode 331: Total Reward = -138.0\n",
      "Episode 332: Total Reward = -171.0\n",
      "Episode 333: Total Reward = -146.0\n",
      "Episode 334: Total Reward = -147.0\n",
      "Episode 335: Total Reward = -89.0\n",
      "Episode 336: Total Reward = -123.0\n",
      "Episode 337: Total Reward = -113.0\n",
      "Episode 338: Total Reward = -153.0\n",
      "Episode 339: Total Reward = -107.0\n",
      "Episode 340: Total Reward = -145.0\n",
      "Episode 341: Total Reward = -107.0\n",
      "Episode 342: Total Reward = -89.0\n",
      "Episode 343: Total Reward = -89.0\n",
      "Episode 344: Total Reward = -148.0\n",
      "Episode 345: Total Reward = -149.0\n",
      "Episode 346: Total Reward = -98.0\n",
      "Episode 347: Total Reward = -138.0\n",
      "Episode 348: Total Reward = -106.0\n",
      "Episode 349: Total Reward = -107.0\n",
      "Episode 350: Total Reward = -111.0\n",
      "Episode 351: Total Reward = -107.0\n",
      "Episode 352: Total Reward = -109.0\n",
      "Episode 353: Total Reward = -151.0\n",
      "Episode 354: Total Reward = -147.0\n",
      "Episode 355: Total Reward = -113.0\n",
      "Episode 356: Total Reward = -145.0\n",
      "Episode 357: Total Reward = -111.0\n",
      "Episode 358: Total Reward = -147.0\n",
      "Episode 359: Total Reward = -111.0\n",
      "Episode 360: Total Reward = -143.0\n",
      "Episode 361: Total Reward = -107.0\n",
      "Episode 362: Total Reward = -139.0\n",
      "Episode 363: Total Reward = -108.0\n",
      "Episode 364: Total Reward = -101.0\n",
      "Episode 365: Total Reward = -107.0\n",
      "Episode 366: Total Reward = -108.0\n",
      "Episode 367: Total Reward = -107.0\n",
      "Episode 368: Total Reward = -108.0\n",
      "Episode 369: Total Reward = -152.0\n",
      "Episode 370: Total Reward = -85.0\n",
      "Episode 371: Total Reward = -106.0\n",
      "Episode 372: Total Reward = -144.0\n",
      "Episode 373: Total Reward = -107.0\n",
      "Episode 374: Total Reward = -102.0\n",
      "Episode 375: Total Reward = -135.0\n",
      "Episode 376: Total Reward = -145.0\n",
      "Episode 377: Total Reward = -151.0\n",
      "Episode 378: Total Reward = -96.0\n",
      "Episode 379: Total Reward = -157.0\n",
      "Episode 380: Total Reward = -110.0\n",
      "Episode 381: Total Reward = -173.0\n",
      "Episode 382: Total Reward = -155.0\n",
      "Episode 383: Total Reward = -153.0\n",
      "Episode 384: Total Reward = -152.0\n",
      "Episode 385: Total Reward = -146.0\n",
      "Episode 386: Total Reward = -101.0\n",
      "Episode 387: Total Reward = -118.0\n",
      "Episode 388: Total Reward = -152.0\n",
      "Episode 389: Total Reward = -148.0\n",
      "Episode 390: Total Reward = -106.0\n",
      "Episode 391: Total Reward = -139.0\n",
      "Episode 392: Total Reward = -146.0\n",
      "Episode 393: Total Reward = -118.0\n",
      "Episode 394: Total Reward = -153.0\n",
      "Episode 395: Total Reward = -185.0\n",
      "Episode 396: Total Reward = -105.0\n",
      "Episode 397: Total Reward = -150.0\n",
      "Episode 398: Total Reward = -106.0\n",
      "Episode 399: Total Reward = -165.0\n",
      "Episode 400: Total Reward = -102.0\n",
      "Episode 401: Total Reward = -105.0\n",
      "Episode 402: Total Reward = -159.0\n",
      "Episode 403: Total Reward = -107.0\n",
      "Episode 404: Total Reward = -164.0\n",
      "Episode 405: Total Reward = -95.0\n",
      "Episode 406: Total Reward = -88.0\n",
      "Episode 407: Total Reward = -104.0\n",
      "Episode 408: Total Reward = -143.0\n",
      "Episode 409: Total Reward = -158.0\n",
      "Episode 410: Total Reward = -106.0\n",
      "Episode 411: Total Reward = -106.0\n",
      "Episode 412: Total Reward = -155.0\n",
      "Episode 413: Total Reward = -152.0\n",
      "Episode 414: Total Reward = -150.0\n",
      "Episode 415: Total Reward = -147.0\n",
      "Episode 416: Total Reward = -108.0\n",
      "Episode 417: Total Reward = -152.0\n",
      "Episode 418: Total Reward = -126.0\n",
      "Episode 419: Total Reward = -106.0\n",
      "Episode 420: Total Reward = -149.0\n",
      "Episode 421: Total Reward = -141.0\n",
      "Episode 422: Total Reward = -145.0\n",
      "Episode 423: Total Reward = -108.0\n",
      "Episode 424: Total Reward = -146.0\n",
      "Episode 425: Total Reward = -151.0\n",
      "Episode 426: Total Reward = -106.0\n",
      "Episode 427: Total Reward = -165.0\n",
      "Episode 428: Total Reward = -141.0\n",
      "Episode 429: Total Reward = -141.0\n",
      "Episode 430: Total Reward = -140.0\n",
      "Episode 431: Total Reward = -120.0\n",
      "Episode 432: Total Reward = -147.0\n",
      "Episode 433: Total Reward = -90.0\n",
      "Episode 434: Total Reward = -135.0\n",
      "Episode 435: Total Reward = -150.0\n",
      "Episode 436: Total Reward = -105.0\n",
      "Episode 437: Total Reward = -112.0\n",
      "Episode 438: Total Reward = -149.0\n",
      "Episode 439: Total Reward = -104.0\n",
      "Episode 440: Total Reward = -106.0\n",
      "Episode 441: Total Reward = -109.0\n",
      "Episode 442: Total Reward = -107.0\n",
      "Episode 443: Total Reward = -180.0\n",
      "Episode 444: Total Reward = -106.0\n",
      "Episode 445: Total Reward = -155.0\n",
      "Episode 446: Total Reward = -90.0\n",
      "Episode 447: Total Reward = -101.0\n",
      "Episode 448: Total Reward = -140.0\n",
      "Episode 449: Total Reward = -145.0\n",
      "Episode 450: Total Reward = -148.0\n",
      "Episode 451: Total Reward = -108.0\n",
      "Episode 452: Total Reward = -105.0\n",
      "Episode 453: Total Reward = -106.0\n",
      "Episode 454: Total Reward = -108.0\n",
      "Episode 455: Total Reward = -109.0\n",
      "Episode 456: Total Reward = -107.0\n",
      "Episode 457: Total Reward = -109.0\n",
      "Episode 458: Total Reward = -113.0\n",
      "Episode 459: Total Reward = -87.0\n",
      "Episode 460: Total Reward = -99.0\n",
      "Episode 461: Total Reward = -107.0\n",
      "Episode 462: Total Reward = -106.0\n",
      "Episode 463: Total Reward = -150.0\n",
      "Episode 464: Total Reward = -141.0\n",
      "Episode 465: Total Reward = -106.0\n",
      "Episode 466: Total Reward = -99.0\n",
      "Episode 467: Total Reward = -108.0\n",
      "Episode 468: Total Reward = -108.0\n",
      "Episode 469: Total Reward = -106.0\n",
      "Episode 470: Total Reward = -106.0\n",
      "Episode 471: Total Reward = -106.0\n",
      "Episode 472: Total Reward = -146.0\n",
      "Episode 473: Total Reward = -109.0\n",
      "Episode 474: Total Reward = -90.0\n",
      "Episode 475: Total Reward = -89.0\n",
      "Episode 476: Total Reward = -90.0\n",
      "Episode 477: Total Reward = -119.0\n",
      "Episode 478: Total Reward = -106.0\n",
      "Episode 479: Total Reward = -85.0\n",
      "Episode 480: Total Reward = -160.0\n",
      "Episode 481: Total Reward = -98.0\n",
      "Episode 482: Total Reward = -88.0\n",
      "Episode 483: Total Reward = -87.0\n",
      "Episode 484: Total Reward = -87.0\n",
      "Episode 485: Total Reward = -106.0\n",
      "Episode 486: Total Reward = -97.0\n",
      "Episode 487: Total Reward = -142.0\n",
      "Episode 488: Total Reward = -132.0\n",
      "Episode 489: Total Reward = -143.0\n",
      "Episode 490: Total Reward = -132.0\n",
      "Episode 491: Total Reward = -115.0\n",
      "Episode 492: Total Reward = -118.0\n",
      "Episode 493: Total Reward = -108.0\n",
      "Episode 494: Total Reward = -108.0\n",
      "Episode 495: Total Reward = -108.0\n",
      "Episode 496: Total Reward = -111.0\n",
      "Episode 497: Total Reward = -108.0\n",
      "Episode 498: Total Reward = -108.0\n",
      "Episode 499: Total Reward = -92.0\n",
      "Episode 500: Total Reward = -107.0\n",
      "Episode 501: Total Reward = -108.0\n",
      "Episode 502: Total Reward = -108.0\n",
      "Episode 503: Total Reward = -85.0\n",
      "Episode 504: Total Reward = -89.0\n",
      "Episode 505: Total Reward = -109.0\n",
      "Episode 506: Total Reward = -105.0\n",
      "Episode 507: Total Reward = -141.0\n",
      "Episode 508: Total Reward = -104.0\n",
      "Episode 509: Total Reward = -168.0\n",
      "Episode 510: Total Reward = -110.0\n",
      "Episode 511: Total Reward = -138.0\n",
      "Episode 512: Total Reward = -107.0\n",
      "Episode 513: Total Reward = -147.0\n",
      "Episode 514: Total Reward = -107.0\n",
      "Episode 515: Total Reward = -143.0\n",
      "Episode 516: Total Reward = -106.0\n",
      "Episode 517: Total Reward = -106.0\n",
      "Episode 518: Total Reward = -106.0\n",
      "Episode 519: Total Reward = -106.0\n",
      "Episode 520: Total Reward = -154.0\n",
      "Episode 521: Total Reward = -145.0\n",
      "Episode 522: Total Reward = -97.0\n",
      "Episode 523: Total Reward = -141.0\n",
      "Episode 524: Total Reward = -146.0\n",
      "Episode 525: Total Reward = -107.0\n",
      "Episode 526: Total Reward = -153.0\n",
      "Episode 527: Total Reward = -106.0\n",
      "Episode 528: Total Reward = -106.0\n",
      "Episode 529: Total Reward = -106.0\n",
      "Episode 530: Total Reward = -107.0\n",
      "Episode 531: Total Reward = -94.0\n",
      "Episode 532: Total Reward = -108.0\n",
      "Episode 533: Total Reward = -181.0\n",
      "Episode 534: Total Reward = -142.0\n",
      "Episode 535: Total Reward = -140.0\n",
      "Episode 536: Total Reward = -142.0\n",
      "Episode 537: Total Reward = -109.0\n",
      "Episode 538: Total Reward = -154.0\n",
      "Episode 539: Total Reward = -145.0\n",
      "Episode 540: Total Reward = -148.0\n",
      "Episode 541: Total Reward = -166.0\n",
      "Episode 542: Total Reward = -112.0\n",
      "Episode 543: Total Reward = -116.0\n",
      "Episode 544: Total Reward = -107.0\n",
      "Episode 545: Total Reward = -153.0\n",
      "Episode 546: Total Reward = -143.0\n",
      "Episode 547: Total Reward = -109.0\n",
      "Episode 548: Total Reward = -106.0\n",
      "Episode 549: Total Reward = -94.0\n",
      "Episode 550: Total Reward = -106.0\n",
      "Episode 551: Total Reward = -87.0\n",
      "Episode 552: Total Reward = -94.0\n",
      "Episode 553: Total Reward = -142.0\n",
      "Episode 554: Total Reward = -107.0\n",
      "Episode 555: Total Reward = -181.0\n",
      "Episode 556: Total Reward = -151.0\n",
      "Episode 557: Total Reward = -101.0\n",
      "Episode 558: Total Reward = -163.0\n",
      "Episode 559: Total Reward = -158.0\n",
      "Episode 560: Total Reward = -152.0\n",
      "Episode 561: Total Reward = -108.0\n",
      "Episode 562: Total Reward = -154.0\n",
      "Episode 563: Total Reward = -106.0\n",
      "Episode 564: Total Reward = -107.0\n",
      "Episode 565: Total Reward = -107.0\n",
      "Episode 566: Total Reward = -152.0\n",
      "Episode 567: Total Reward = -151.0\n",
      "Episode 568: Total Reward = -109.0\n",
      "Episode 569: Total Reward = -108.0\n",
      "Episode 570: Total Reward = -106.0\n",
      "Episode 571: Total Reward = -109.0\n",
      "Episode 572: Total Reward = -158.0\n",
      "Episode 573: Total Reward = -108.0\n",
      "Episode 574: Total Reward = -143.0\n",
      "Episode 575: Total Reward = -123.0\n",
      "Episode 576: Total Reward = -114.0\n",
      "Episode 577: Total Reward = -112.0\n",
      "Episode 578: Total Reward = -106.0\n",
      "Episode 579: Total Reward = -108.0\n",
      "Episode 580: Total Reward = -108.0\n",
      "Episode 581: Total Reward = -148.0\n",
      "Episode 582: Total Reward = -108.0\n",
      "Episode 583: Total Reward = -104.0\n",
      "Episode 584: Total Reward = -146.0\n",
      "Episode 585: Total Reward = -109.0\n",
      "Episode 586: Total Reward = -118.0\n",
      "Episode 587: Total Reward = -106.0\n",
      "Episode 588: Total Reward = -159.0\n",
      "Episode 589: Total Reward = -107.0\n",
      "Episode 590: Total Reward = -87.0\n",
      "Episode 591: Total Reward = -105.0\n",
      "Episode 592: Total Reward = -89.0\n",
      "Episode 593: Total Reward = -100.0\n",
      "Episode 594: Total Reward = -106.0\n",
      "Episode 595: Total Reward = -99.0\n",
      "Episode 596: Total Reward = -105.0\n",
      "Episode 597: Total Reward = -153.0\n",
      "Episode 598: Total Reward = -155.0\n",
      "Episode 599: Total Reward = -145.0\n",
      "Episode 600: Total Reward = -93.0\n",
      "Episode 601: Total Reward = -107.0\n",
      "Episode 602: Total Reward = -139.0\n",
      "Episode 603: Total Reward = -151.0\n",
      "Episode 604: Total Reward = -195.0\n",
      "Episode 605: Total Reward = -143.0\n",
      "Episode 606: Total Reward = -140.0\n",
      "Episode 607: Total Reward = -155.0\n",
      "Episode 608: Total Reward = -158.0\n",
      "Episode 609: Total Reward = -141.0\n",
      "Episode 610: Total Reward = -149.0\n",
      "Episode 611: Total Reward = -139.0\n",
      "Episode 612: Total Reward = -146.0\n",
      "Episode 613: Total Reward = -122.0\n",
      "Episode 614: Total Reward = -106.0\n",
      "Episode 615: Total Reward = -167.0\n",
      "Episode 616: Total Reward = -151.0\n",
      "Episode 617: Total Reward = -146.0\n",
      "Episode 618: Total Reward = -151.0\n",
      "Episode 619: Total Reward = -148.0\n",
      "Episode 620: Total Reward = -153.0\n",
      "Episode 621: Total Reward = -129.0\n",
      "Episode 622: Total Reward = -113.0\n",
      "Episode 623: Total Reward = -108.0\n",
      "Episode 624: Total Reward = -111.0\n",
      "Episode 625: Total Reward = -104.0\n",
      "Episode 626: Total Reward = -109.0\n",
      "Episode 627: Total Reward = -152.0\n",
      "Episode 628: Total Reward = -144.0\n",
      "Episode 629: Total Reward = -107.0\n",
      "Episode 630: Total Reward = -107.0\n",
      "Episode 631: Total Reward = -90.0\n",
      "Episode 632: Total Reward = -105.0\n",
      "Episode 633: Total Reward = -106.0\n",
      "Episode 634: Total Reward = -161.0\n",
      "Episode 635: Total Reward = -103.0\n",
      "Episode 636: Total Reward = -106.0\n",
      "Episode 637: Total Reward = -154.0\n",
      "Episode 638: Total Reward = -145.0\n",
      "Episode 639: Total Reward = -92.0\n",
      "Episode 640: Total Reward = -142.0\n",
      "Episode 641: Total Reward = -124.0\n",
      "Episode 642: Total Reward = -104.0\n",
      "Episode 643: Total Reward = -165.0\n",
      "Episode 644: Total Reward = -105.0\n",
      "Episode 645: Total Reward = -86.0\n",
      "Episode 646: Total Reward = -161.0\n",
      "Episode 647: Total Reward = -105.0\n",
      "Episode 648: Total Reward = -152.0\n",
      "Episode 649: Total Reward = -91.0\n",
      "Episode 650: Total Reward = -106.0\n",
      "Episode 651: Total Reward = -139.0\n",
      "Episode 652: Total Reward = -91.0\n",
      "Episode 653: Total Reward = -135.0\n",
      "Episode 654: Total Reward = -111.0\n",
      "Episode 655: Total Reward = -144.0\n",
      "Episode 656: Total Reward = -138.0\n",
      "Episode 657: Total Reward = -105.0\n",
      "Episode 658: Total Reward = -150.0\n",
      "Episode 659: Total Reward = -143.0\n",
      "Episode 660: Total Reward = -148.0\n",
      "Episode 661: Total Reward = -146.0\n",
      "Episode 662: Total Reward = -106.0\n",
      "Episode 663: Total Reward = -132.0\n",
      "Episode 664: Total Reward = -101.0\n",
      "Episode 665: Total Reward = -100.0\n",
      "Episode 666: Total Reward = -139.0\n",
      "Episode 667: Total Reward = -141.0\n",
      "Episode 668: Total Reward = -136.0\n",
      "Episode 669: Total Reward = -134.0\n",
      "Episode 670: Total Reward = -139.0\n",
      "Episode 671: Total Reward = -109.0\n",
      "Episode 672: Total Reward = -107.0\n",
      "Episode 673: Total Reward = -155.0\n",
      "Episode 674: Total Reward = -142.0\n",
      "Episode 675: Total Reward = -108.0\n",
      "Episode 676: Total Reward = -107.0\n",
      "Episode 677: Total Reward = -146.0\n",
      "Episode 678: Total Reward = -146.0\n",
      "Episode 679: Total Reward = -144.0\n",
      "Episode 680: Total Reward = -159.0\n",
      "Episode 681: Total Reward = -97.0\n",
      "Episode 682: Total Reward = -159.0\n",
      "Episode 683: Total Reward = -89.0\n",
      "Episode 684: Total Reward = -166.0\n",
      "Episode 685: Total Reward = -85.0\n",
      "Episode 686: Total Reward = -89.0\n",
      "Episode 687: Total Reward = -143.0\n",
      "Episode 688: Total Reward = -90.0\n",
      "Episode 689: Total Reward = -96.0\n",
      "Episode 690: Total Reward = -144.0\n",
      "Episode 691: Total Reward = -142.0\n",
      "Episode 692: Total Reward = -135.0\n",
      "Episode 693: Total Reward = -142.0\n",
      "Episode 694: Total Reward = -138.0\n",
      "Episode 695: Total Reward = -93.0\n",
      "Episode 696: Total Reward = -156.0\n",
      "Episode 697: Total Reward = -165.0\n",
      "Episode 698: Total Reward = -144.0\n",
      "Episode 699: Total Reward = -147.0\n",
      "Episode 700: Total Reward = -109.0\n",
      "Episode 701: Total Reward = -143.0\n",
      "Episode 702: Total Reward = -113.0\n",
      "Episode 703: Total Reward = -111.0\n",
      "Episode 704: Total Reward = -138.0\n",
      "Episode 705: Total Reward = -109.0\n",
      "Episode 706: Total Reward = -125.0\n",
      "Episode 707: Total Reward = -200.0\n",
      "Episode 708: Total Reward = -117.0\n",
      "Episode 709: Total Reward = -109.0\n",
      "Episode 710: Total Reward = -110.0\n",
      "Episode 711: Total Reward = -112.0\n",
      "Episode 712: Total Reward = -112.0\n",
      "Episode 713: Total Reward = -114.0\n",
      "Episode 714: Total Reward = -125.0\n",
      "Episode 715: Total Reward = -115.0\n",
      "Episode 716: Total Reward = -120.0\n",
      "Episode 717: Total Reward = -141.0\n",
      "Episode 718: Total Reward = -137.0\n",
      "Episode 719: Total Reward = -109.0\n",
      "Episode 720: Total Reward = -145.0\n",
      "Episode 721: Total Reward = -142.0\n",
      "Episode 722: Total Reward = -111.0\n",
      "Episode 723: Total Reward = -117.0\n",
      "Episode 724: Total Reward = -144.0\n",
      "Episode 725: Total Reward = -154.0\n",
      "Episode 726: Total Reward = -112.0\n",
      "Episode 727: Total Reward = -109.0\n",
      "Episode 728: Total Reward = -109.0\n",
      "Episode 729: Total Reward = -111.0\n",
      "Episode 730: Total Reward = -110.0\n",
      "Episode 731: Total Reward = -107.0\n",
      "Episode 732: Total Reward = -142.0\n",
      "Episode 733: Total Reward = -107.0\n",
      "Episode 734: Total Reward = -146.0\n",
      "Episode 735: Total Reward = -139.0\n",
      "Episode 736: Total Reward = -128.0\n",
      "Episode 737: Total Reward = -150.0\n",
      "Episode 738: Total Reward = -143.0\n",
      "Episode 739: Total Reward = -114.0\n",
      "Episode 740: Total Reward = -136.0\n",
      "Episode 741: Total Reward = -136.0\n",
      "Episode 742: Total Reward = -134.0\n",
      "Episode 743: Total Reward = -144.0\n",
      "Episode 744: Total Reward = -134.0\n",
      "Episode 745: Total Reward = -149.0\n",
      "Episode 746: Total Reward = -132.0\n",
      "Episode 747: Total Reward = -144.0\n",
      "Episode 748: Total Reward = -146.0\n",
      "Episode 749: Total Reward = -138.0\n",
      "Episode 750: Total Reward = -138.0\n",
      "Episode 751: Total Reward = -144.0\n",
      "Episode 752: Total Reward = -147.0\n",
      "Episode 753: Total Reward = -150.0\n",
      "Episode 754: Total Reward = -162.0\n",
      "Episode 755: Total Reward = -99.0\n",
      "Episode 756: Total Reward = -87.0\n",
      "Episode 757: Total Reward = -145.0\n",
      "Episode 758: Total Reward = -93.0\n",
      "Episode 759: Total Reward = -153.0\n",
      "Episode 760: Total Reward = -138.0\n",
      "Episode 761: Total Reward = -153.0\n",
      "Episode 762: Total Reward = -105.0\n",
      "Episode 763: Total Reward = -139.0\n",
      "Episode 764: Total Reward = -93.0\n",
      "Episode 765: Total Reward = -105.0\n",
      "Episode 766: Total Reward = -87.0\n",
      "Episode 767: Total Reward = -89.0\n",
      "Episode 768: Total Reward = -158.0\n",
      "Episode 769: Total Reward = -101.0\n",
      "Episode 770: Total Reward = -108.0\n",
      "Episode 771: Total Reward = -86.0\n",
      "Episode 772: Total Reward = -101.0\n",
      "Episode 773: Total Reward = -94.0\n",
      "Episode 774: Total Reward = -155.0\n",
      "Episode 775: Total Reward = -134.0\n",
      "Episode 776: Total Reward = -136.0\n",
      "Episode 777: Total Reward = -140.0\n",
      "Episode 778: Total Reward = -146.0\n",
      "Episode 779: Total Reward = -140.0\n",
      "Episode 780: Total Reward = -139.0\n",
      "Episode 781: Total Reward = -144.0\n",
      "Episode 782: Total Reward = -158.0\n",
      "Episode 783: Total Reward = -143.0\n",
      "Episode 784: Total Reward = -145.0\n",
      "Episode 785: Total Reward = -116.0\n",
      "Episode 786: Total Reward = -142.0\n",
      "Episode 787: Total Reward = -188.0\n",
      "Episode 788: Total Reward = -160.0\n",
      "Episode 789: Total Reward = -145.0\n",
      "Episode 790: Total Reward = -136.0\n",
      "Episode 791: Total Reward = -111.0\n",
      "Episode 792: Total Reward = -98.0\n",
      "Episode 793: Total Reward = -91.0\n",
      "Episode 794: Total Reward = -155.0\n",
      "Episode 795: Total Reward = -110.0\n",
      "Episode 796: Total Reward = -142.0\n",
      "Episode 797: Total Reward = -144.0\n",
      "Episode 798: Total Reward = -92.0\n",
      "Episode 799: Total Reward = -93.0\n",
      "Episode 800: Total Reward = -111.0\n",
      "Episode 801: Total Reward = -151.0\n",
      "Episode 802: Total Reward = -153.0\n",
      "Episode 803: Total Reward = -168.0\n",
      "Episode 804: Total Reward = -150.0\n",
      "Episode 805: Total Reward = -148.0\n",
      "Episode 806: Total Reward = -137.0\n",
      "Episode 807: Total Reward = -121.0\n",
      "Episode 808: Total Reward = -134.0\n",
      "Episode 809: Total Reward = -112.0\n",
      "Episode 810: Total Reward = -101.0\n",
      "Episode 811: Total Reward = -95.0\n",
      "Episode 812: Total Reward = -98.0\n",
      "Episode 813: Total Reward = -96.0\n",
      "Episode 814: Total Reward = -138.0\n",
      "Episode 815: Total Reward = -136.0\n",
      "Episode 816: Total Reward = -174.0\n",
      "Episode 817: Total Reward = -154.0\n",
      "Episode 818: Total Reward = -83.0\n",
      "Episode 819: Total Reward = -92.0\n",
      "Episode 820: Total Reward = -145.0\n",
      "Episode 821: Total Reward = -90.0\n",
      "Episode 822: Total Reward = -146.0\n",
      "Episode 823: Total Reward = -150.0\n",
      "Episode 824: Total Reward = -142.0\n",
      "Episode 825: Total Reward = -158.0\n",
      "Episode 826: Total Reward = -125.0\n",
      "Episode 827: Total Reward = -90.0\n",
      "Episode 828: Total Reward = -108.0\n",
      "Episode 829: Total Reward = -143.0\n",
      "Episode 830: Total Reward = -105.0\n",
      "Episode 831: Total Reward = -108.0\n",
      "Episode 832: Total Reward = -90.0\n",
      "Episode 833: Total Reward = -159.0\n",
      "Episode 834: Total Reward = -141.0\n",
      "Episode 835: Total Reward = -148.0\n",
      "Episode 836: Total Reward = -138.0\n",
      "Episode 837: Total Reward = -142.0\n",
      "Episode 838: Total Reward = -150.0\n",
      "Episode 839: Total Reward = -109.0\n",
      "Episode 840: Total Reward = -134.0\n",
      "Episode 841: Total Reward = -137.0\n",
      "Episode 842: Total Reward = -137.0\n",
      "Episode 843: Total Reward = -108.0\n",
      "Episode 844: Total Reward = -107.0\n",
      "Episode 845: Total Reward = -107.0\n",
      "Episode 846: Total Reward = -107.0\n",
      "Episode 847: Total Reward = -107.0\n",
      "Episode 848: Total Reward = -108.0\n",
      "Episode 849: Total Reward = -107.0\n",
      "Episode 850: Total Reward = -89.0\n",
      "Episode 851: Total Reward = -107.0\n",
      "Episode 852: Total Reward = -108.0\n",
      "Episode 853: Total Reward = -106.0\n",
      "Episode 854: Total Reward = -87.0\n",
      "Episode 855: Total Reward = -84.0\n",
      "Episode 856: Total Reward = -106.0\n",
      "Episode 857: Total Reward = -142.0\n",
      "Episode 858: Total Reward = -149.0\n",
      "Episode 859: Total Reward = -148.0\n",
      "Episode 860: Total Reward = -142.0\n",
      "Episode 861: Total Reward = -113.0\n",
      "Episode 862: Total Reward = -95.0\n",
      "Episode 863: Total Reward = -153.0\n",
      "Episode 864: Total Reward = -141.0\n",
      "Episode 865: Total Reward = -116.0\n",
      "Episode 866: Total Reward = -142.0\n",
      "Episode 867: Total Reward = -88.0\n",
      "Episode 868: Total Reward = -180.0\n",
      "Episode 869: Total Reward = -138.0\n",
      "Episode 870: Total Reward = -93.0\n",
      "Episode 871: Total Reward = -102.0\n",
      "Episode 872: Total Reward = -147.0\n",
      "Episode 873: Total Reward = -133.0\n",
      "Episode 874: Total Reward = -114.0\n",
      "Episode 875: Total Reward = -110.0\n",
      "Episode 876: Total Reward = -110.0\n",
      "Episode 877: Total Reward = -108.0\n",
      "Episode 878: Total Reward = -108.0\n",
      "Episode 879: Total Reward = -107.0\n",
      "Episode 880: Total Reward = -108.0\n",
      "Episode 881: Total Reward = -194.0\n",
      "Episode 882: Total Reward = -116.0\n",
      "Episode 883: Total Reward = -111.0\n",
      "Episode 884: Total Reward = -105.0\n",
      "Episode 885: Total Reward = -93.0\n",
      "Episode 886: Total Reward = -150.0\n",
      "Episode 887: Total Reward = -142.0\n",
      "Episode 888: Total Reward = -84.0\n",
      "Episode 889: Total Reward = -85.0\n",
      "Episode 890: Total Reward = -88.0\n",
      "Episode 891: Total Reward = -90.0\n",
      "Episode 892: Total Reward = -112.0\n",
      "Episode 893: Total Reward = -107.0\n",
      "Episode 894: Total Reward = -92.0\n",
      "Episode 895: Total Reward = -159.0\n",
      "Episode 896: Total Reward = -97.0\n",
      "Episode 897: Total Reward = -89.0\n",
      "Episode 898: Total Reward = -144.0\n",
      "Episode 899: Total Reward = -88.0\n",
      "Episode 900: Total Reward = -146.0\n",
      "Episode 901: Total Reward = -160.0\n",
      "Episode 902: Total Reward = -86.0\n",
      "Episode 903: Total Reward = -140.0\n",
      "Episode 904: Total Reward = -139.0\n",
      "Episode 905: Total Reward = -153.0\n",
      "Episode 906: Total Reward = -137.0\n",
      "Episode 907: Total Reward = -136.0\n",
      "Episode 908: Total Reward = -115.0\n",
      "Episode 909: Total Reward = -92.0\n",
      "Episode 910: Total Reward = -143.0\n",
      "Episode 911: Total Reward = -107.0\n",
      "Episode 912: Total Reward = -108.0\n",
      "Episode 913: Total Reward = -105.0\n",
      "Episode 914: Total Reward = -153.0\n",
      "Episode 915: Total Reward = -143.0\n",
      "Episode 916: Total Reward = -139.0\n",
      "Episode 917: Total Reward = -106.0\n",
      "Episode 918: Total Reward = -144.0\n",
      "Episode 919: Total Reward = -140.0\n",
      "Episode 920: Total Reward = -140.0\n",
      "Episode 921: Total Reward = -143.0\n",
      "Episode 922: Total Reward = -138.0\n",
      "Episode 923: Total Reward = -106.0\n",
      "Episode 924: Total Reward = -86.0\n",
      "Episode 925: Total Reward = -103.0\n",
      "Episode 926: Total Reward = -106.0\n",
      "Episode 927: Total Reward = -101.0\n",
      "Episode 928: Total Reward = -137.0\n",
      "Episode 929: Total Reward = -109.0\n",
      "Episode 930: Total Reward = -137.0\n",
      "Episode 931: Total Reward = -139.0\n",
      "Episode 932: Total Reward = -87.0\n",
      "Episode 933: Total Reward = -154.0\n",
      "Episode 934: Total Reward = -148.0\n",
      "Episode 935: Total Reward = -145.0\n",
      "Episode 936: Total Reward = -105.0\n",
      "Episode 937: Total Reward = -86.0\n",
      "Episode 938: Total Reward = -148.0\n",
      "Episode 939: Total Reward = -111.0\n",
      "Episode 940: Total Reward = -148.0\n",
      "Episode 941: Total Reward = -150.0\n",
      "Episode 942: Total Reward = -105.0\n",
      "Episode 943: Total Reward = -149.0\n",
      "Episode 944: Total Reward = -146.0\n",
      "Episode 945: Total Reward = -89.0\n",
      "Episode 946: Total Reward = -107.0\n",
      "Episode 947: Total Reward = -99.0\n",
      "Episode 948: Total Reward = -105.0\n",
      "Episode 949: Total Reward = -102.0\n",
      "Episode 950: Total Reward = -142.0\n",
      "Episode 951: Total Reward = -95.0\n",
      "Episode 952: Total Reward = -147.0\n",
      "Episode 953: Total Reward = -140.0\n",
      "Episode 954: Total Reward = -139.0\n",
      "Episode 955: Total Reward = -86.0\n",
      "Episode 956: Total Reward = -111.0\n",
      "Episode 957: Total Reward = -137.0\n",
      "Episode 958: Total Reward = -90.0\n",
      "Episode 959: Total Reward = -146.0\n",
      "Episode 960: Total Reward = -106.0\n",
      "Episode 961: Total Reward = -104.0\n",
      "Episode 962: Total Reward = -109.0\n",
      "Episode 963: Total Reward = -110.0\n",
      "Episode 964: Total Reward = -87.0\n",
      "Episode 965: Total Reward = -141.0\n",
      "Episode 966: Total Reward = -160.0\n",
      "Episode 967: Total Reward = -111.0\n",
      "Episode 968: Total Reward = -108.0\n",
      "Episode 969: Total Reward = -101.0\n",
      "Episode 970: Total Reward = -109.0\n",
      "Episode 971: Total Reward = -175.0\n",
      "Episode 972: Total Reward = -88.0\n",
      "Episode 973: Total Reward = -148.0\n",
      "Episode 974: Total Reward = -109.0\n",
      "Episode 975: Total Reward = -152.0\n",
      "Episode 976: Total Reward = -111.0\n",
      "Episode 977: Total Reward = -165.0\n",
      "Episode 978: Total Reward = -143.0\n",
      "Episode 979: Total Reward = -157.0\n",
      "Episode 980: Total Reward = -111.0\n",
      "Episode 981: Total Reward = -95.0\n",
      "Episode 982: Total Reward = -109.0\n",
      "Episode 983: Total Reward = -150.0\n",
      "Episode 984: Total Reward = -151.0\n",
      "Episode 985: Total Reward = -142.0\n",
      "Episode 986: Total Reward = -151.0\n",
      "Episode 987: Total Reward = -136.0\n",
      "Episode 988: Total Reward = -161.0\n",
      "Episode 989: Total Reward = -136.0\n",
      "Episode 990: Total Reward = -138.0\n",
      "Episode 991: Total Reward = -184.0\n",
      "Episode 992: Total Reward = -119.0\n",
      "Episode 993: Total Reward = -159.0\n",
      "Episode 994: Total Reward = -112.0\n",
      "Episode 995: Total Reward = -107.0\n",
      "Episode 996: Total Reward = -84.0\n",
      "Episode 997: Total Reward = -106.0\n",
      "Episode 998: Total Reward = -89.0\n",
      "Episode 999: Total Reward = -152.0\n",
      "Episode 1000: Total Reward = -109.0\n"
     ]
    }
   ],
   "source": [
    "# Run SARSA\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "num_actions = env.action_space.n\n",
    "Q = sarsa_mountain_car(episodes=1000, alpha=0.1, gamma=0.99, epsilon=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -200.0\n",
      "Episode 2: Total Reward = -200.0\n",
      "Episode 3: Total Reward = -200.0\n",
      "Episode 4: Total Reward = -200.0\n",
      "Episode 5: Total Reward = -200.0\n",
      "Episode 6: Total Reward = -200.0\n",
      "Episode 7: Total Reward = -200.0\n",
      "Episode 8: Total Reward = -200.0\n",
      "Episode 9: Total Reward = -200.0\n",
      "Episode 10: Total Reward = -200.0\n",
      "Episode 11: Total Reward = -200.0\n",
      "Episode 12: Total Reward = -200.0\n",
      "Episode 13: Total Reward = -200.0\n",
      "Episode 14: Total Reward = -200.0\n",
      "Episode 15: Total Reward = -200.0\n",
      "Episode 16: Total Reward = -200.0\n",
      "Episode 17: Total Reward = -170.0\n",
      "Episode 18: Total Reward = -200.0\n",
      "Episode 19: Total Reward = -182.0\n",
      "Episode 20: Total Reward = -200.0\n",
      "Episode 21: Total Reward = -200.0\n",
      "Episode 22: Total Reward = -200.0\n",
      "Episode 23: Total Reward = -200.0\n",
      "Episode 24: Total Reward = -200.0\n",
      "Episode 25: Total Reward = -164.0\n",
      "Episode 26: Total Reward = -173.0\n",
      "Episode 27: Total Reward = -199.0\n",
      "Episode 28: Total Reward = -200.0\n",
      "Episode 29: Total Reward = -199.0\n",
      "Episode 30: Total Reward = -200.0\n",
      "Episode 31: Total Reward = -200.0\n",
      "Episode 32: Total Reward = -158.0\n",
      "Episode 33: Total Reward = -200.0\n",
      "Episode 34: Total Reward = -200.0\n",
      "Episode 35: Total Reward = -200.0\n",
      "Episode 36: Total Reward = -200.0\n",
      "Episode 37: Total Reward = -194.0\n",
      "Episode 38: Total Reward = -200.0\n",
      "Episode 39: Total Reward = -120.0\n",
      "Episode 40: Total Reward = -200.0\n",
      "Episode 41: Total Reward = -112.0\n",
      "Episode 42: Total Reward = -200.0\n",
      "Episode 43: Total Reward = -200.0\n",
      "Episode 44: Total Reward = -200.0\n",
      "Episode 45: Total Reward = -200.0\n",
      "Episode 46: Total Reward = -200.0\n",
      "Episode 47: Total Reward = -200.0\n",
      "Episode 48: Total Reward = -200.0\n",
      "Episode 49: Total Reward = -148.0\n",
      "Episode 50: Total Reward = -157.0\n",
      "Episode 51: Total Reward = -151.0\n",
      "Episode 52: Total Reward = -162.0\n",
      "Episode 53: Total Reward = -200.0\n",
      "Episode 54: Total Reward = -200.0\n",
      "Episode 55: Total Reward = -185.0\n",
      "Episode 56: Total Reward = -152.0\n",
      "Episode 57: Total Reward = -150.0\n",
      "Episode 58: Total Reward = -152.0\n",
      "Episode 59: Total Reward = -179.0\n",
      "Episode 60: Total Reward = -152.0\n",
      "Episode 61: Total Reward = -132.0\n",
      "Episode 62: Total Reward = -156.0\n",
      "Episode 63: Total Reward = -149.0\n",
      "Episode 64: Total Reward = -166.0\n",
      "Episode 65: Total Reward = -162.0\n",
      "Episode 66: Total Reward = -157.0\n",
      "Episode 67: Total Reward = -149.0\n",
      "Episode 68: Total Reward = -146.0\n",
      "Episode 69: Total Reward = -154.0\n",
      "Episode 70: Total Reward = -152.0\n",
      "Episode 71: Total Reward = -145.0\n",
      "Episode 72: Total Reward = -148.0\n",
      "Episode 73: Total Reward = -159.0\n",
      "Episode 74: Total Reward = -131.0\n",
      "Episode 75: Total Reward = -113.0\n",
      "Episode 76: Total Reward = -149.0\n",
      "Episode 77: Total Reward = -188.0\n",
      "Episode 78: Total Reward = -152.0\n",
      "Episode 79: Total Reward = -159.0\n",
      "Episode 80: Total Reward = -122.0\n",
      "Episode 81: Total Reward = -154.0\n",
      "Episode 82: Total Reward = -146.0\n",
      "Episode 83: Total Reward = -200.0\n",
      "Episode 84: Total Reward = -115.0\n",
      "Episode 85: Total Reward = -120.0\n",
      "Episode 86: Total Reward = -151.0\n",
      "Episode 87: Total Reward = -147.0\n",
      "Episode 88: Total Reward = -114.0\n",
      "Episode 89: Total Reward = -122.0\n",
      "Episode 90: Total Reward = -92.0\n",
      "Episode 91: Total Reward = -116.0\n",
      "Episode 92: Total Reward = -84.0\n",
      "Episode 93: Total Reward = -118.0\n",
      "Episode 94: Total Reward = -115.0\n",
      "Episode 95: Total Reward = -149.0\n",
      "Episode 96: Total Reward = -101.0\n",
      "Episode 97: Total Reward = -89.0\n",
      "Episode 98: Total Reward = -148.0\n",
      "Episode 99: Total Reward = -146.0\n",
      "Episode 100: Total Reward = -147.0\n",
      "Episode 101: Total Reward = -150.0\n",
      "Episode 102: Total Reward = -158.0\n",
      "Episode 103: Total Reward = -117.0\n",
      "Episode 104: Total Reward = -114.0\n",
      "Episode 105: Total Reward = -152.0\n",
      "Episode 106: Total Reward = -172.0\n",
      "Episode 107: Total Reward = -110.0\n",
      "Episode 108: Total Reward = -95.0\n",
      "Episode 109: Total Reward = -113.0\n",
      "Episode 110: Total Reward = -110.0\n",
      "Episode 111: Total Reward = -111.0\n",
      "Episode 112: Total Reward = -109.0\n",
      "Episode 113: Total Reward = -107.0\n",
      "Episode 114: Total Reward = -116.0\n",
      "Episode 115: Total Reward = -103.0\n",
      "Episode 116: Total Reward = -159.0\n",
      "Episode 117: Total Reward = -109.0\n",
      "Episode 118: Total Reward = -152.0\n",
      "Episode 119: Total Reward = -139.0\n",
      "Episode 120: Total Reward = -185.0\n",
      "Episode 121: Total Reward = -154.0\n",
      "Episode 122: Total Reward = -140.0\n",
      "Episode 123: Total Reward = -146.0\n",
      "Episode 124: Total Reward = -154.0\n",
      "Episode 125: Total Reward = -118.0\n",
      "Episode 126: Total Reward = -142.0\n",
      "Episode 127: Total Reward = -145.0\n",
      "Episode 128: Total Reward = -109.0\n",
      "Episode 129: Total Reward = -145.0\n",
      "Episode 130: Total Reward = -144.0\n",
      "Episode 131: Total Reward = -187.0\n",
      "Episode 132: Total Reward = -111.0\n",
      "Episode 133: Total Reward = -152.0\n",
      "Episode 134: Total Reward = -156.0\n",
      "Episode 135: Total Reward = -143.0\n",
      "Episode 136: Total Reward = -131.0\n",
      "Episode 137: Total Reward = -156.0\n",
      "Episode 138: Total Reward = -106.0\n",
      "Episode 139: Total Reward = -142.0\n",
      "Episode 140: Total Reward = -162.0\n",
      "Episode 141: Total Reward = -159.0\n",
      "Episode 142: Total Reward = -108.0\n",
      "Episode 143: Total Reward = -128.0\n",
      "Episode 144: Total Reward = -108.0\n",
      "Episode 145: Total Reward = -119.0\n",
      "Episode 146: Total Reward = -121.0\n",
      "Episode 147: Total Reward = -150.0\n",
      "Episode 148: Total Reward = -152.0\n",
      "Episode 149: Total Reward = -149.0\n",
      "Episode 150: Total Reward = -144.0\n",
      "Episode 151: Total Reward = -149.0\n",
      "Episode 152: Total Reward = -148.0\n",
      "Episode 153: Total Reward = -137.0\n",
      "Episode 154: Total Reward = -155.0\n",
      "Episode 155: Total Reward = -175.0\n",
      "Episode 156: Total Reward = -108.0\n",
      "Episode 157: Total Reward = -157.0\n",
      "Episode 158: Total Reward = -155.0\n",
      "Episode 159: Total Reward = -156.0\n",
      "Episode 160: Total Reward = -155.0\n",
      "Episode 161: Total Reward = -135.0\n",
      "Episode 162: Total Reward = -140.0\n",
      "Episode 163: Total Reward = -105.0\n",
      "Episode 164: Total Reward = -141.0\n",
      "Episode 165: Total Reward = -145.0\n",
      "Episode 166: Total Reward = -147.0\n",
      "Episode 167: Total Reward = -138.0\n",
      "Episode 168: Total Reward = -152.0\n",
      "Episode 169: Total Reward = -112.0\n",
      "Episode 170: Total Reward = -147.0\n",
      "Episode 171: Total Reward = -155.0\n",
      "Episode 172: Total Reward = -155.0\n",
      "Episode 173: Total Reward = -141.0\n",
      "Episode 174: Total Reward = -153.0\n",
      "Episode 175: Total Reward = -146.0\n",
      "Episode 176: Total Reward = -149.0\n",
      "Episode 177: Total Reward = -140.0\n",
      "Episode 178: Total Reward = -142.0\n",
      "Episode 179: Total Reward = -147.0\n",
      "Episode 180: Total Reward = -144.0\n",
      "Episode 181: Total Reward = -109.0\n",
      "Episode 182: Total Reward = -145.0\n",
      "Episode 183: Total Reward = -145.0\n",
      "Episode 184: Total Reward = -140.0\n",
      "Episode 185: Total Reward = -174.0\n",
      "Episode 186: Total Reward = -143.0\n",
      "Episode 187: Total Reward = -138.0\n",
      "Episode 188: Total Reward = -152.0\n",
      "Episode 189: Total Reward = -155.0\n",
      "Episode 190: Total Reward = -133.0\n",
      "Episode 191: Total Reward = -178.0\n",
      "Episode 192: Total Reward = -180.0\n",
      "Episode 193: Total Reward = -154.0\n",
      "Episode 194: Total Reward = -125.0\n",
      "Episode 195: Total Reward = -152.0\n",
      "Episode 196: Total Reward = -140.0\n",
      "Episode 197: Total Reward = -110.0\n",
      "Episode 198: Total Reward = -151.0\n",
      "Episode 199: Total Reward = -146.0\n",
      "Episode 200: Total Reward = -148.0\n",
      "Episode 201: Total Reward = -146.0\n",
      "Episode 202: Total Reward = -148.0\n",
      "Episode 203: Total Reward = -110.0\n",
      "Episode 204: Total Reward = -135.0\n",
      "Episode 205: Total Reward = -129.0\n",
      "Episode 206: Total Reward = -151.0\n",
      "Episode 207: Total Reward = -166.0\n",
      "Episode 208: Total Reward = -166.0\n",
      "Episode 209: Total Reward = -163.0\n",
      "Episode 210: Total Reward = -162.0\n",
      "Episode 211: Total Reward = -149.0\n",
      "Episode 212: Total Reward = -111.0\n",
      "Episode 213: Total Reward = -153.0\n",
      "Episode 214: Total Reward = -110.0\n",
      "Episode 215: Total Reward = -160.0\n",
      "Episode 216: Total Reward = -145.0\n",
      "Episode 217: Total Reward = -154.0\n",
      "Episode 218: Total Reward = -87.0\n",
      "Episode 219: Total Reward = -90.0\n",
      "Episode 220: Total Reward = -151.0\n",
      "Episode 221: Total Reward = -150.0\n",
      "Episode 222: Total Reward = -116.0\n",
      "Episode 223: Total Reward = -106.0\n",
      "Episode 224: Total Reward = -145.0\n",
      "Episode 225: Total Reward = -139.0\n",
      "Episode 226: Total Reward = -175.0\n",
      "Episode 227: Total Reward = -148.0\n",
      "Episode 228: Total Reward = -142.0\n",
      "Episode 229: Total Reward = -142.0\n",
      "Episode 230: Total Reward = -148.0\n",
      "Episode 231: Total Reward = -110.0\n",
      "Episode 232: Total Reward = -160.0\n",
      "Episode 233: Total Reward = -138.0\n",
      "Episode 234: Total Reward = -109.0\n",
      "Episode 235: Total Reward = -91.0\n",
      "Episode 236: Total Reward = -114.0\n",
      "Episode 237: Total Reward = -151.0\n",
      "Episode 238: Total Reward = -159.0\n",
      "Episode 239: Total Reward = -112.0\n",
      "Episode 240: Total Reward = -88.0\n",
      "Episode 241: Total Reward = -146.0\n",
      "Episode 242: Total Reward = -114.0\n",
      "Episode 243: Total Reward = -92.0\n",
      "Episode 244: Total Reward = -144.0\n",
      "Episode 245: Total Reward = -108.0\n",
      "Episode 246: Total Reward = -91.0\n",
      "Episode 247: Total Reward = -156.0\n",
      "Episode 248: Total Reward = -110.0\n",
      "Episode 249: Total Reward = -90.0\n",
      "Episode 250: Total Reward = -156.0\n",
      "Episode 251: Total Reward = -135.0\n",
      "Episode 252: Total Reward = -158.0\n",
      "Episode 253: Total Reward = -165.0\n",
      "Episode 254: Total Reward = -108.0\n",
      "Episode 255: Total Reward = -94.0\n",
      "Episode 256: Total Reward = -159.0\n",
      "Episode 257: Total Reward = -108.0\n",
      "Episode 258: Total Reward = -92.0\n",
      "Episode 259: Total Reward = -106.0\n",
      "Episode 260: Total Reward = -112.0\n",
      "Episode 261: Total Reward = -111.0\n",
      "Episode 262: Total Reward = -90.0\n",
      "Episode 263: Total Reward = -91.0\n",
      "Episode 264: Total Reward = -89.0\n",
      "Episode 265: Total Reward = -172.0\n",
      "Episode 266: Total Reward = -90.0\n",
      "Episode 267: Total Reward = -90.0\n",
      "Episode 268: Total Reward = -153.0\n",
      "Episode 269: Total Reward = -144.0\n",
      "Episode 270: Total Reward = -141.0\n",
      "Episode 271: Total Reward = -141.0\n",
      "Episode 272: Total Reward = -144.0\n",
      "Episode 273: Total Reward = -154.0\n",
      "Episode 274: Total Reward = -106.0\n",
      "Episode 275: Total Reward = -88.0\n",
      "Episode 276: Total Reward = -106.0\n",
      "Episode 277: Total Reward = -159.0\n",
      "Episode 278: Total Reward = -146.0\n",
      "Episode 279: Total Reward = -142.0\n",
      "Episode 280: Total Reward = -88.0\n",
      "Episode 281: Total Reward = -149.0\n",
      "Episode 282: Total Reward = -128.0\n",
      "Episode 283: Total Reward = -141.0\n",
      "Episode 284: Total Reward = -89.0\n",
      "Episode 285: Total Reward = -148.0\n",
      "Episode 286: Total Reward = -147.0\n",
      "Episode 287: Total Reward = -153.0\n",
      "Episode 288: Total Reward = -167.0\n",
      "Episode 289: Total Reward = -143.0\n",
      "Episode 290: Total Reward = -153.0\n",
      "Episode 291: Total Reward = -143.0\n",
      "Episode 292: Total Reward = -134.0\n",
      "Episode 293: Total Reward = -109.0\n",
      "Episode 294: Total Reward = -100.0\n",
      "Episode 295: Total Reward = -136.0\n",
      "Episode 296: Total Reward = -146.0\n",
      "Episode 297: Total Reward = -110.0\n",
      "Episode 298: Total Reward = -105.0\n",
      "Episode 299: Total Reward = -109.0\n",
      "Episode 300: Total Reward = -107.0\n",
      "Episode 301: Total Reward = -108.0\n",
      "Episode 302: Total Reward = -107.0\n",
      "Episode 303: Total Reward = -106.0\n",
      "Episode 304: Total Reward = -106.0\n",
      "Episode 305: Total Reward = -105.0\n",
      "Episode 306: Total Reward = -160.0\n",
      "Episode 307: Total Reward = -143.0\n",
      "Episode 308: Total Reward = -141.0\n",
      "Episode 309: Total Reward = -131.0\n",
      "Episode 310: Total Reward = -89.0\n",
      "Episode 311: Total Reward = -106.0\n",
      "Episode 312: Total Reward = -106.0\n",
      "Episode 313: Total Reward = -106.0\n",
      "Episode 314: Total Reward = -112.0\n",
      "Episode 315: Total Reward = -107.0\n",
      "Episode 316: Total Reward = -107.0\n",
      "Episode 317: Total Reward = -166.0\n",
      "Episode 318: Total Reward = -161.0\n",
      "Episode 319: Total Reward = -138.0\n",
      "Episode 320: Total Reward = -150.0\n",
      "Episode 321: Total Reward = -107.0\n",
      "Episode 322: Total Reward = -138.0\n",
      "Episode 323: Total Reward = -87.0\n",
      "Episode 324: Total Reward = -135.0\n",
      "Episode 325: Total Reward = -105.0\n",
      "Episode 326: Total Reward = -159.0\n",
      "Episode 327: Total Reward = -86.0\n",
      "Episode 328: Total Reward = -156.0\n",
      "Episode 329: Total Reward = -141.0\n",
      "Episode 330: Total Reward = -87.0\n",
      "Episode 331: Total Reward = -155.0\n",
      "Episode 332: Total Reward = -133.0\n",
      "Episode 333: Total Reward = -134.0\n",
      "Episode 334: Total Reward = -138.0\n",
      "Episode 335: Total Reward = -104.0\n",
      "Episode 336: Total Reward = -149.0\n",
      "Episode 337: Total Reward = -104.0\n",
      "Episode 338: Total Reward = -104.0\n",
      "Episode 339: Total Reward = -105.0\n",
      "Episode 340: Total Reward = -87.0\n",
      "Episode 341: Total Reward = -86.0\n",
      "Episode 342: Total Reward = -94.0\n",
      "Episode 343: Total Reward = -105.0\n",
      "Episode 344: Total Reward = -152.0\n",
      "Episode 345: Total Reward = -100.0\n",
      "Episode 346: Total Reward = -158.0\n",
      "Episode 347: Total Reward = -108.0\n",
      "Episode 348: Total Reward = -139.0\n",
      "Episode 349: Total Reward = -134.0\n",
      "Episode 350: Total Reward = -151.0\n",
      "Episode 351: Total Reward = -104.0\n",
      "Episode 352: Total Reward = -141.0\n",
      "Episode 353: Total Reward = -151.0\n",
      "Episode 354: Total Reward = -84.0\n",
      "Episode 355: Total Reward = -146.0\n",
      "Episode 356: Total Reward = -142.0\n",
      "Episode 357: Total Reward = -143.0\n",
      "Episode 358: Total Reward = -104.0\n",
      "Episode 359: Total Reward = -92.0\n",
      "Episode 360: Total Reward = -104.0\n",
      "Episode 361: Total Reward = -92.0\n",
      "Episode 362: Total Reward = -140.0\n",
      "Episode 363: Total Reward = -196.0\n",
      "Episode 364: Total Reward = -106.0\n",
      "Episode 365: Total Reward = -104.0\n",
      "Episode 366: Total Reward = -106.0\n",
      "Episode 367: Total Reward = -138.0\n",
      "Episode 368: Total Reward = -106.0\n",
      "Episode 369: Total Reward = -96.0\n",
      "Episode 370: Total Reward = -84.0\n",
      "Episode 371: Total Reward = -170.0\n",
      "Episode 372: Total Reward = -88.0\n",
      "Episode 373: Total Reward = -89.0\n",
      "Episode 374: Total Reward = -146.0\n",
      "Episode 375: Total Reward = -143.0\n",
      "Episode 376: Total Reward = -107.0\n",
      "Episode 377: Total Reward = -95.0\n",
      "Episode 378: Total Reward = -147.0\n",
      "Episode 379: Total Reward = -140.0\n",
      "Episode 380: Total Reward = -109.0\n",
      "Episode 381: Total Reward = -99.0\n",
      "Episode 382: Total Reward = -88.0\n",
      "Episode 383: Total Reward = -105.0\n",
      "Episode 384: Total Reward = -109.0\n",
      "Episode 385: Total Reward = -105.0\n",
      "Episode 386: Total Reward = -137.0\n",
      "Episode 387: Total Reward = -105.0\n",
      "Episode 388: Total Reward = -107.0\n",
      "Episode 389: Total Reward = -86.0\n",
      "Episode 390: Total Reward = -92.0\n",
      "Episode 391: Total Reward = -134.0\n",
      "Episode 392: Total Reward = -143.0\n",
      "Episode 393: Total Reward = -86.0\n",
      "Episode 394: Total Reward = -138.0\n",
      "Episode 395: Total Reward = -84.0\n",
      "Episode 396: Total Reward = -138.0\n",
      "Episode 397: Total Reward = -108.0\n",
      "Episode 398: Total Reward = -106.0\n",
      "Episode 399: Total Reward = -136.0\n",
      "Episode 400: Total Reward = -111.0\n",
      "Episode 401: Total Reward = -84.0\n",
      "Episode 402: Total Reward = -85.0\n",
      "Episode 403: Total Reward = -106.0\n",
      "Episode 404: Total Reward = -143.0\n",
      "Episode 405: Total Reward = -85.0\n",
      "Episode 406: Total Reward = -137.0\n",
      "Episode 407: Total Reward = -135.0\n",
      "Episode 408: Total Reward = -125.0\n",
      "Episode 409: Total Reward = -107.0\n",
      "Episode 410: Total Reward = -154.0\n",
      "Episode 411: Total Reward = -160.0\n",
      "Episode 412: Total Reward = -91.0\n",
      "Episode 413: Total Reward = -137.0\n",
      "Episode 414: Total Reward = -149.0\n",
      "Episode 415: Total Reward = -130.0\n",
      "Episode 416: Total Reward = -145.0\n",
      "Episode 417: Total Reward = -138.0\n",
      "Episode 418: Total Reward = -159.0\n",
      "Episode 419: Total Reward = -87.0\n",
      "Episode 420: Total Reward = -85.0\n",
      "Episode 421: Total Reward = -88.0\n",
      "Episode 422: Total Reward = -141.0\n",
      "Episode 423: Total Reward = -140.0\n",
      "Episode 424: Total Reward = -140.0\n",
      "Episode 425: Total Reward = -138.0\n",
      "Episode 426: Total Reward = -139.0\n",
      "Episode 427: Total Reward = -125.0\n",
      "Episode 428: Total Reward = -106.0\n",
      "Episode 429: Total Reward = -106.0\n",
      "Episode 430: Total Reward = -136.0\n",
      "Episode 431: Total Reward = -101.0\n",
      "Episode 432: Total Reward = -107.0\n",
      "Episode 433: Total Reward = -136.0\n",
      "Episode 434: Total Reward = -183.0\n",
      "Episode 435: Total Reward = -93.0\n",
      "Episode 436: Total Reward = -84.0\n",
      "Episode 437: Total Reward = -144.0\n",
      "Episode 438: Total Reward = -97.0\n",
      "Episode 439: Total Reward = -116.0\n",
      "Episode 440: Total Reward = -97.0\n",
      "Episode 441: Total Reward = -141.0\n",
      "Episode 442: Total Reward = -152.0\n",
      "Episode 443: Total Reward = -156.0\n",
      "Episode 444: Total Reward = -149.0\n",
      "Episode 445: Total Reward = -86.0\n",
      "Episode 446: Total Reward = -107.0\n",
      "Episode 447: Total Reward = -86.0\n",
      "Episode 448: Total Reward = -85.0\n",
      "Episode 449: Total Reward = -83.0\n",
      "Episode 450: Total Reward = -92.0\n",
      "Episode 451: Total Reward = -94.0\n",
      "Episode 452: Total Reward = -108.0\n",
      "Episode 453: Total Reward = -106.0\n",
      "Episode 454: Total Reward = -106.0\n",
      "Episode 455: Total Reward = -148.0\n",
      "Episode 456: Total Reward = -167.0\n",
      "Episode 457: Total Reward = -105.0\n",
      "Episode 458: Total Reward = -105.0\n",
      "Episode 459: Total Reward = -163.0\n",
      "Episode 460: Total Reward = -95.0\n",
      "Episode 461: Total Reward = -105.0\n",
      "Episode 462: Total Reward = -107.0\n",
      "Episode 463: Total Reward = -135.0\n",
      "Episode 464: Total Reward = -154.0\n",
      "Episode 465: Total Reward = -107.0\n",
      "Episode 466: Total Reward = -106.0\n",
      "Episode 467: Total Reward = -106.0\n",
      "Episode 468: Total Reward = -135.0\n",
      "Episode 469: Total Reward = -147.0\n",
      "Episode 470: Total Reward = -137.0\n",
      "Episode 471: Total Reward = -94.0\n",
      "Episode 472: Total Reward = -106.0\n",
      "Episode 473: Total Reward = -139.0\n",
      "Episode 474: Total Reward = -139.0\n",
      "Episode 475: Total Reward = -106.0\n",
      "Episode 476: Total Reward = -92.0\n",
      "Episode 477: Total Reward = -152.0\n",
      "Episode 478: Total Reward = -94.0\n",
      "Episode 479: Total Reward = -139.0\n",
      "Episode 480: Total Reward = -90.0\n",
      "Episode 481: Total Reward = -137.0\n",
      "Episode 482: Total Reward = -139.0\n",
      "Episode 483: Total Reward = -142.0\n",
      "Episode 484: Total Reward = -136.0\n",
      "Episode 485: Total Reward = -164.0\n",
      "Episode 486: Total Reward = -109.0\n",
      "Episode 487: Total Reward = -87.0\n",
      "Episode 488: Total Reward = -109.0\n",
      "Episode 489: Total Reward = -106.0\n",
      "Episode 490: Total Reward = -152.0\n",
      "Episode 491: Total Reward = -90.0\n",
      "Episode 492: Total Reward = -106.0\n",
      "Episode 493: Total Reward = -93.0\n",
      "Episode 494: Total Reward = -106.0\n",
      "Episode 495: Total Reward = -137.0\n",
      "Episode 496: Total Reward = -131.0\n",
      "Episode 497: Total Reward = -137.0\n",
      "Episode 498: Total Reward = -106.0\n",
      "Episode 499: Total Reward = -105.0\n",
      "Episode 500: Total Reward = -144.0\n",
      "Episode 501: Total Reward = -155.0\n",
      "Episode 502: Total Reward = -97.0\n",
      "Episode 503: Total Reward = -106.0\n",
      "Episode 504: Total Reward = -145.0\n",
      "Episode 505: Total Reward = -106.0\n",
      "Episode 506: Total Reward = -85.0\n",
      "Episode 507: Total Reward = -153.0\n",
      "Episode 508: Total Reward = -150.0\n",
      "Episode 509: Total Reward = -87.0\n",
      "Episode 510: Total Reward = -106.0\n",
      "Episode 511: Total Reward = -140.0\n",
      "Episode 512: Total Reward = -107.0\n",
      "Episode 513: Total Reward = -153.0\n",
      "Episode 514: Total Reward = -145.0\n",
      "Episode 515: Total Reward = -143.0\n",
      "Episode 516: Total Reward = -163.0\n",
      "Episode 517: Total Reward = -111.0\n",
      "Episode 518: Total Reward = -97.0\n",
      "Episode 519: Total Reward = -136.0\n",
      "Episode 520: Total Reward = -139.0\n",
      "Episode 521: Total Reward = -106.0\n",
      "Episode 522: Total Reward = -92.0\n",
      "Episode 523: Total Reward = -105.0\n",
      "Episode 524: Total Reward = -197.0\n",
      "Episode 525: Total Reward = -161.0\n",
      "Episode 526: Total Reward = -158.0\n",
      "Episode 527: Total Reward = -90.0\n",
      "Episode 528: Total Reward = -105.0\n",
      "Episode 529: Total Reward = -96.0\n",
      "Episode 530: Total Reward = -100.0\n",
      "Episode 531: Total Reward = -139.0\n",
      "Episode 532: Total Reward = -138.0\n",
      "Episode 533: Total Reward = -138.0\n",
      "Episode 534: Total Reward = -107.0\n",
      "Episode 535: Total Reward = -142.0\n",
      "Episode 536: Total Reward = -106.0\n",
      "Episode 537: Total Reward = -96.0\n",
      "Episode 538: Total Reward = -106.0\n",
      "Episode 539: Total Reward = -157.0\n",
      "Episode 540: Total Reward = -150.0\n",
      "Episode 541: Total Reward = -107.0\n",
      "Episode 542: Total Reward = -106.0\n",
      "Episode 543: Total Reward = -106.0\n",
      "Episode 544: Total Reward = -172.0\n",
      "Episode 545: Total Reward = -106.0\n",
      "Episode 546: Total Reward = -142.0\n",
      "Episode 547: Total Reward = -135.0\n",
      "Episode 548: Total Reward = -139.0\n",
      "Episode 549: Total Reward = -139.0\n",
      "Episode 550: Total Reward = -106.0\n",
      "Episode 551: Total Reward = -88.0\n",
      "Episode 552: Total Reward = -106.0\n",
      "Episode 553: Total Reward = -106.0\n",
      "Episode 554: Total Reward = -106.0\n",
      "Episode 555: Total Reward = -89.0\n",
      "Episode 556: Total Reward = -183.0\n",
      "Episode 557: Total Reward = -85.0\n",
      "Episode 558: Total Reward = -107.0\n",
      "Episode 559: Total Reward = -148.0\n",
      "Episode 560: Total Reward = -161.0\n",
      "Episode 561: Total Reward = -90.0\n",
      "Episode 562: Total Reward = -105.0\n",
      "Episode 563: Total Reward = -106.0\n",
      "Episode 564: Total Reward = -107.0\n",
      "Episode 565: Total Reward = -107.0\n",
      "Episode 566: Total Reward = -107.0\n",
      "Episode 567: Total Reward = -107.0\n",
      "Episode 568: Total Reward = -107.0\n",
      "Episode 569: Total Reward = -88.0\n",
      "Episode 570: Total Reward = -91.0\n",
      "Episode 571: Total Reward = -86.0\n",
      "Episode 572: Total Reward = -107.0\n",
      "Episode 573: Total Reward = -97.0\n",
      "Episode 574: Total Reward = -102.0\n",
      "Episode 575: Total Reward = -140.0\n",
      "Episode 576: Total Reward = -171.0\n",
      "Episode 577: Total Reward = -153.0\n",
      "Episode 578: Total Reward = -86.0\n",
      "Episode 579: Total Reward = -138.0\n",
      "Episode 580: Total Reward = -152.0\n",
      "Episode 581: Total Reward = -103.0\n",
      "Episode 582: Total Reward = -133.0\n",
      "Episode 583: Total Reward = -124.0\n",
      "Episode 584: Total Reward = -142.0\n",
      "Episode 585: Total Reward = -93.0\n",
      "Episode 586: Total Reward = -135.0\n",
      "Episode 587: Total Reward = -135.0\n",
      "Episode 588: Total Reward = -137.0\n",
      "Episode 589: Total Reward = -106.0\n",
      "Episode 590: Total Reward = -147.0\n",
      "Episode 591: Total Reward = -139.0\n",
      "Episode 592: Total Reward = -139.0\n",
      "Episode 593: Total Reward = -141.0\n",
      "Episode 594: Total Reward = -109.0\n",
      "Episode 595: Total Reward = -110.0\n",
      "Episode 596: Total Reward = -149.0\n",
      "Episode 597: Total Reward = -111.0\n",
      "Episode 598: Total Reward = -91.0\n",
      "Episode 599: Total Reward = -142.0\n",
      "Episode 600: Total Reward = -149.0\n",
      "Episode 601: Total Reward = -156.0\n",
      "Episode 602: Total Reward = -106.0\n",
      "Episode 603: Total Reward = -106.0\n",
      "Episode 604: Total Reward = -105.0\n",
      "Episode 605: Total Reward = -150.0\n",
      "Episode 606: Total Reward = -105.0\n",
      "Episode 607: Total Reward = -105.0\n",
      "Episode 608: Total Reward = -150.0\n",
      "Episode 609: Total Reward = -157.0\n",
      "Episode 610: Total Reward = -87.0\n",
      "Episode 611: Total Reward = -137.0\n",
      "Episode 612: Total Reward = -106.0\n",
      "Episode 613: Total Reward = -110.0\n",
      "Episode 614: Total Reward = -107.0\n",
      "Episode 615: Total Reward = -95.0\n",
      "Episode 616: Total Reward = -175.0\n",
      "Episode 617: Total Reward = -85.0\n",
      "Episode 618: Total Reward = -92.0\n",
      "Episode 619: Total Reward = -105.0\n",
      "Episode 620: Total Reward = -106.0\n",
      "Episode 621: Total Reward = -87.0\n",
      "Episode 622: Total Reward = -88.0\n",
      "Episode 623: Total Reward = -107.0\n",
      "Episode 624: Total Reward = -154.0\n",
      "Episode 625: Total Reward = -153.0\n",
      "Episode 626: Total Reward = -147.0\n",
      "Episode 627: Total Reward = -159.0\n",
      "Episode 628: Total Reward = -140.0\n",
      "Episode 629: Total Reward = -109.0\n",
      "Episode 630: Total Reward = -91.0\n",
      "Episode 631: Total Reward = -142.0\n",
      "Episode 632: Total Reward = -109.0\n",
      "Episode 633: Total Reward = -108.0\n",
      "Episode 634: Total Reward = -138.0\n",
      "Episode 635: Total Reward = -85.0\n",
      "Episode 636: Total Reward = -142.0\n",
      "Episode 637: Total Reward = -109.0\n",
      "Episode 638: Total Reward = -84.0\n",
      "Episode 639: Total Reward = -107.0\n",
      "Episode 640: Total Reward = -83.0\n",
      "Episode 641: Total Reward = -138.0\n",
      "Episode 642: Total Reward = -155.0\n",
      "Episode 643: Total Reward = -138.0\n",
      "Episode 644: Total Reward = -133.0\n",
      "Episode 645: Total Reward = -140.0\n",
      "Episode 646: Total Reward = -104.0\n",
      "Episode 647: Total Reward = -86.0\n",
      "Episode 648: Total Reward = -144.0\n",
      "Episode 649: Total Reward = -88.0\n",
      "Episode 650: Total Reward = -94.0\n",
      "Episode 651: Total Reward = -147.0\n",
      "Episode 652: Total Reward = -139.0\n",
      "Episode 653: Total Reward = -85.0\n",
      "Episode 654: Total Reward = -124.0\n",
      "Episode 655: Total Reward = -99.0\n",
      "Episode 656: Total Reward = -140.0\n",
      "Episode 657: Total Reward = -106.0\n",
      "Episode 658: Total Reward = -109.0\n",
      "Episode 659: Total Reward = -93.0\n",
      "Episode 660: Total Reward = -106.0\n",
      "Episode 661: Total Reward = -107.0\n",
      "Episode 662: Total Reward = -105.0\n",
      "Episode 663: Total Reward = -105.0\n",
      "Episode 664: Total Reward = -105.0\n",
      "Episode 665: Total Reward = -90.0\n",
      "Episode 666: Total Reward = -105.0\n",
      "Episode 667: Total Reward = -85.0\n",
      "Episode 668: Total Reward = -85.0\n",
      "Episode 669: Total Reward = -107.0\n",
      "Episode 670: Total Reward = -107.0\n",
      "Episode 671: Total Reward = -85.0\n",
      "Episode 672: Total Reward = -107.0\n",
      "Episode 673: Total Reward = -151.0\n",
      "Episode 674: Total Reward = -149.0\n",
      "Episode 675: Total Reward = -104.0\n",
      "Episode 676: Total Reward = -105.0\n",
      "Episode 677: Total Reward = -84.0\n",
      "Episode 678: Total Reward = -107.0\n",
      "Episode 679: Total Reward = -156.0\n",
      "Episode 680: Total Reward = -88.0\n",
      "Episode 681: Total Reward = -104.0\n",
      "Episode 682: Total Reward = -85.0\n",
      "Episode 683: Total Reward = -98.0\n",
      "Episode 684: Total Reward = -147.0\n",
      "Episode 685: Total Reward = -105.0\n",
      "Episode 686: Total Reward = -105.0\n",
      "Episode 687: Total Reward = -130.0\n",
      "Episode 688: Total Reward = -84.0\n",
      "Episode 689: Total Reward = -139.0\n",
      "Episode 690: Total Reward = -137.0\n",
      "Episode 691: Total Reward = -139.0\n",
      "Episode 692: Total Reward = -128.0\n",
      "Episode 693: Total Reward = -175.0\n",
      "Episode 694: Total Reward = -97.0\n",
      "Episode 695: Total Reward = -83.0\n",
      "Episode 696: Total Reward = -149.0\n",
      "Episode 697: Total Reward = -138.0\n",
      "Episode 698: Total Reward = -83.0\n",
      "Episode 699: Total Reward = -85.0\n",
      "Episode 700: Total Reward = -106.0\n",
      "Episode 701: Total Reward = -139.0\n",
      "Episode 702: Total Reward = -104.0\n",
      "Episode 703: Total Reward = -86.0\n",
      "Episode 704: Total Reward = -142.0\n",
      "Episode 705: Total Reward = -152.0\n",
      "Episode 706: Total Reward = -85.0\n",
      "Episode 707: Total Reward = -146.0\n",
      "Episode 708: Total Reward = -96.0\n",
      "Episode 709: Total Reward = -87.0\n",
      "Episode 710: Total Reward = -136.0\n",
      "Episode 711: Total Reward = -127.0\n",
      "Episode 712: Total Reward = -104.0\n",
      "Episode 713: Total Reward = -105.0\n",
      "Episode 714: Total Reward = -104.0\n",
      "Episode 715: Total Reward = -90.0\n",
      "Episode 716: Total Reward = -86.0\n",
      "Episode 717: Total Reward = -160.0\n",
      "Episode 718: Total Reward = -106.0\n",
      "Episode 719: Total Reward = -84.0\n",
      "Episode 720: Total Reward = -137.0\n",
      "Episode 721: Total Reward = -107.0\n",
      "Episode 722: Total Reward = -106.0\n",
      "Episode 723: Total Reward = -109.0\n",
      "Episode 724: Total Reward = -86.0\n",
      "Episode 725: Total Reward = -92.0\n",
      "Episode 726: Total Reward = -89.0\n",
      "Episode 727: Total Reward = -105.0\n",
      "Episode 728: Total Reward = -105.0\n",
      "Episode 729: Total Reward = -84.0\n",
      "Episode 730: Total Reward = -154.0\n",
      "Episode 731: Total Reward = -119.0\n",
      "Episode 732: Total Reward = -127.0\n",
      "Episode 733: Total Reward = -108.0\n",
      "Episode 734: Total Reward = -106.0\n",
      "Episode 735: Total Reward = -138.0\n",
      "Episode 736: Total Reward = -128.0\n",
      "Episode 737: Total Reward = -136.0\n",
      "Episode 738: Total Reward = -134.0\n",
      "Episode 739: Total Reward = -92.0\n",
      "Episode 740: Total Reward = -109.0\n",
      "Episode 741: Total Reward = -161.0\n",
      "Episode 742: Total Reward = -98.0\n",
      "Episode 743: Total Reward = -149.0\n",
      "Episode 744: Total Reward = -89.0\n",
      "Episode 745: Total Reward = -88.0\n",
      "Episode 746: Total Reward = -144.0\n",
      "Episode 747: Total Reward = -141.0\n",
      "Episode 748: Total Reward = -133.0\n",
      "Episode 749: Total Reward = -138.0\n",
      "Episode 750: Total Reward = -136.0\n",
      "Episode 751: Total Reward = -137.0\n",
      "Episode 752: Total Reward = -146.0\n",
      "Episode 753: Total Reward = -142.0\n",
      "Episode 754: Total Reward = -85.0\n",
      "Episode 755: Total Reward = -88.0\n",
      "Episode 756: Total Reward = -106.0\n",
      "Episode 757: Total Reward = -97.0\n",
      "Episode 758: Total Reward = -142.0\n",
      "Episode 759: Total Reward = -91.0\n",
      "Episode 760: Total Reward = -137.0\n",
      "Episode 761: Total Reward = -106.0\n",
      "Episode 762: Total Reward = -112.0\n",
      "Episode 763: Total Reward = -104.0\n",
      "Episode 764: Total Reward = -105.0\n",
      "Episode 765: Total Reward = -106.0\n",
      "Episode 766: Total Reward = -106.0\n",
      "Episode 767: Total Reward = -106.0\n",
      "Episode 768: Total Reward = -106.0\n",
      "Episode 769: Total Reward = -104.0\n",
      "Episode 770: Total Reward = -104.0\n",
      "Episode 771: Total Reward = -107.0\n",
      "Episode 772: Total Reward = -85.0\n",
      "Episode 773: Total Reward = -154.0\n",
      "Episode 774: Total Reward = -159.0\n",
      "Episode 775: Total Reward = -143.0\n",
      "Episode 776: Total Reward = -105.0\n",
      "Episode 777: Total Reward = -105.0\n",
      "Episode 778: Total Reward = -92.0\n",
      "Episode 779: Total Reward = -87.0\n",
      "Episode 780: Total Reward = -141.0\n",
      "Episode 781: Total Reward = -165.0\n",
      "Episode 782: Total Reward = -136.0\n",
      "Episode 783: Total Reward = -138.0\n",
      "Episode 784: Total Reward = -139.0\n",
      "Episode 785: Total Reward = -107.0\n",
      "Episode 786: Total Reward = -139.0\n",
      "Episode 787: Total Reward = -144.0\n",
      "Episode 788: Total Reward = -104.0\n",
      "Episode 789: Total Reward = -86.0\n",
      "Episode 790: Total Reward = -143.0\n",
      "Episode 791: Total Reward = -87.0\n",
      "Episode 792: Total Reward = -91.0\n",
      "Episode 793: Total Reward = -108.0\n",
      "Episode 794: Total Reward = -144.0\n",
      "Episode 795: Total Reward = -98.0\n",
      "Episode 796: Total Reward = -88.0\n",
      "Episode 797: Total Reward = -97.0\n",
      "Episode 798: Total Reward = -150.0\n",
      "Episode 799: Total Reward = -85.0\n",
      "Episode 800: Total Reward = -137.0\n",
      "Episode 801: Total Reward = -99.0\n",
      "Episode 802: Total Reward = -105.0\n",
      "Episode 803: Total Reward = -107.0\n",
      "Episode 804: Total Reward = -86.0\n",
      "Episode 805: Total Reward = -143.0\n",
      "Episode 806: Total Reward = -106.0\n",
      "Episode 807: Total Reward = -106.0\n",
      "Episode 808: Total Reward = -105.0\n",
      "Episode 809: Total Reward = -90.0\n",
      "Episode 810: Total Reward = -107.0\n",
      "Episode 811: Total Reward = -89.0\n",
      "Episode 812: Total Reward = -107.0\n",
      "Episode 813: Total Reward = -156.0\n",
      "Episode 814: Total Reward = -87.0\n",
      "Episode 815: Total Reward = -107.0\n",
      "Episode 816: Total Reward = -165.0\n",
      "Episode 817: Total Reward = -85.0\n",
      "Episode 818: Total Reward = -138.0\n",
      "Episode 819: Total Reward = -90.0\n",
      "Episode 820: Total Reward = -141.0\n",
      "Episode 821: Total Reward = -156.0\n",
      "Episode 822: Total Reward = -156.0\n",
      "Episode 823: Total Reward = -146.0\n",
      "Episode 824: Total Reward = -148.0\n",
      "Episode 825: Total Reward = -153.0\n",
      "Episode 826: Total Reward = -152.0\n",
      "Episode 827: Total Reward = -131.0\n",
      "Episode 828: Total Reward = -141.0\n",
      "Episode 829: Total Reward = -106.0\n",
      "Episode 830: Total Reward = -135.0\n",
      "Episode 831: Total Reward = -149.0\n",
      "Episode 832: Total Reward = -132.0\n",
      "Episode 833: Total Reward = -105.0\n",
      "Episode 834: Total Reward = -106.0\n",
      "Episode 835: Total Reward = -147.0\n",
      "Episode 836: Total Reward = -145.0\n",
      "Episode 837: Total Reward = -85.0\n",
      "Episode 838: Total Reward = -145.0\n",
      "Episode 839: Total Reward = -108.0\n",
      "Episode 840: Total Reward = -105.0\n",
      "Episode 841: Total Reward = -97.0\n",
      "Episode 842: Total Reward = -136.0\n",
      "Episode 843: Total Reward = -140.0\n",
      "Episode 844: Total Reward = -99.0\n",
      "Episode 845: Total Reward = -141.0\n",
      "Episode 846: Total Reward = -109.0\n",
      "Episode 847: Total Reward = -136.0\n",
      "Episode 848: Total Reward = -86.0\n",
      "Episode 849: Total Reward = -150.0\n",
      "Episode 850: Total Reward = -135.0\n",
      "Episode 851: Total Reward = -137.0\n",
      "Episode 852: Total Reward = -144.0\n",
      "Episode 853: Total Reward = -97.0\n",
      "Episode 854: Total Reward = -151.0\n",
      "Episode 855: Total Reward = -99.0\n",
      "Episode 856: Total Reward = -149.0\n",
      "Episode 857: Total Reward = -117.0\n",
      "Episode 858: Total Reward = -110.0\n",
      "Episode 859: Total Reward = -140.0\n",
      "Episode 860: Total Reward = -106.0\n",
      "Episode 861: Total Reward = -134.0\n",
      "Episode 862: Total Reward = -105.0\n",
      "Episode 863: Total Reward = -138.0\n",
      "Episode 864: Total Reward = -105.0\n",
      "Episode 865: Total Reward = -85.0\n",
      "Episode 866: Total Reward = -105.0\n",
      "Episode 867: Total Reward = -106.0\n",
      "Episode 868: Total Reward = -109.0\n",
      "Episode 869: Total Reward = -88.0\n",
      "Episode 870: Total Reward = -150.0\n",
      "Episode 871: Total Reward = -150.0\n",
      "Episode 872: Total Reward = -137.0\n",
      "Episode 873: Total Reward = -185.0\n",
      "Episode 874: Total Reward = -96.0\n",
      "Episode 875: Total Reward = -101.0\n",
      "Episode 876: Total Reward = -151.0\n",
      "Episode 877: Total Reward = -146.0\n",
      "Episode 878: Total Reward = -108.0\n",
      "Episode 879: Total Reward = -107.0\n",
      "Episode 880: Total Reward = -90.0\n",
      "Episode 881: Total Reward = -138.0\n",
      "Episode 882: Total Reward = -134.0\n",
      "Episode 883: Total Reward = -128.0\n",
      "Episode 884: Total Reward = -147.0\n",
      "Episode 885: Total Reward = -106.0\n",
      "Episode 886: Total Reward = -106.0\n",
      "Episode 887: Total Reward = -106.0\n",
      "Episode 888: Total Reward = -106.0\n",
      "Episode 889: Total Reward = -133.0\n",
      "Episode 890: Total Reward = -186.0\n",
      "Episode 891: Total Reward = -101.0\n",
      "Episode 892: Total Reward = -139.0\n",
      "Episode 893: Total Reward = -135.0\n",
      "Episode 894: Total Reward = -137.0\n",
      "Episode 895: Total Reward = -137.0\n",
      "Episode 896: Total Reward = -89.0\n",
      "Episode 897: Total Reward = -138.0\n",
      "Episode 898: Total Reward = -140.0\n",
      "Episode 899: Total Reward = -85.0\n",
      "Episode 900: Total Reward = -137.0\n",
      "Episode 901: Total Reward = -104.0\n",
      "Episode 902: Total Reward = -150.0\n",
      "Episode 903: Total Reward = -136.0\n",
      "Episode 904: Total Reward = -104.0\n",
      "Episode 905: Total Reward = -105.0\n",
      "Episode 906: Total Reward = -105.0\n",
      "Episode 907: Total Reward = -109.0\n",
      "Episode 908: Total Reward = -105.0\n",
      "Episode 909: Total Reward = -151.0\n",
      "Episode 910: Total Reward = -119.0\n",
      "Episode 911: Total Reward = -105.0\n",
      "Episode 912: Total Reward = -105.0\n",
      "Episode 913: Total Reward = -106.0\n",
      "Episode 914: Total Reward = -91.0\n",
      "Episode 915: Total Reward = -106.0\n",
      "Episode 916: Total Reward = -106.0\n",
      "Episode 917: Total Reward = -85.0\n",
      "Episode 918: Total Reward = -105.0\n",
      "Episode 919: Total Reward = -103.0\n",
      "Episode 920: Total Reward = -104.0\n",
      "Episode 921: Total Reward = -140.0\n",
      "Episode 922: Total Reward = -104.0\n",
      "Episode 923: Total Reward = -137.0\n",
      "Episode 924: Total Reward = -140.0\n",
      "Episode 925: Total Reward = -105.0\n",
      "Episode 926: Total Reward = -92.0\n",
      "Episode 927: Total Reward = -141.0\n",
      "Episode 928: Total Reward = -105.0\n",
      "Episode 929: Total Reward = -104.0\n",
      "Episode 930: Total Reward = -104.0\n",
      "Episode 931: Total Reward = -152.0\n",
      "Episode 932: Total Reward = -138.0\n",
      "Episode 933: Total Reward = -105.0\n",
      "Episode 934: Total Reward = -105.0\n",
      "Episode 935: Total Reward = -86.0\n",
      "Episode 936: Total Reward = -89.0\n",
      "Episode 937: Total Reward = -105.0\n",
      "Episode 938: Total Reward = -104.0\n",
      "Episode 939: Total Reward = -141.0\n",
      "Episode 940: Total Reward = -133.0\n",
      "Episode 941: Total Reward = -142.0\n",
      "Episode 942: Total Reward = -149.0\n",
      "Episode 943: Total Reward = -154.0\n",
      "Episode 944: Total Reward = -142.0\n",
      "Episode 945: Total Reward = -98.0\n",
      "Episode 946: Total Reward = -148.0\n",
      "Episode 947: Total Reward = -155.0\n",
      "Episode 948: Total Reward = -101.0\n",
      "Episode 949: Total Reward = -123.0\n",
      "Episode 950: Total Reward = -84.0\n",
      "Episode 951: Total Reward = -134.0\n",
      "Episode 952: Total Reward = -150.0\n",
      "Episode 953: Total Reward = -164.0\n",
      "Episode 954: Total Reward = -137.0\n",
      "Episode 955: Total Reward = -85.0\n",
      "Episode 956: Total Reward = -105.0\n",
      "Episode 957: Total Reward = -105.0\n",
      "Episode 958: Total Reward = -165.0\n",
      "Episode 959: Total Reward = -86.0\n",
      "Episode 960: Total Reward = -140.0\n",
      "Episode 961: Total Reward = -137.0\n",
      "Episode 962: Total Reward = -104.0\n",
      "Episode 963: Total Reward = -104.0\n",
      "Episode 964: Total Reward = -98.0\n",
      "Episode 965: Total Reward = -85.0\n",
      "Episode 966: Total Reward = -106.0\n",
      "Episode 967: Total Reward = -107.0\n",
      "Episode 968: Total Reward = -137.0\n",
      "Episode 969: Total Reward = -138.0\n",
      "Episode 970: Total Reward = -88.0\n",
      "Episode 971: Total Reward = -106.0\n",
      "Episode 972: Total Reward = -145.0\n",
      "Episode 973: Total Reward = -105.0\n",
      "Episode 974: Total Reward = -133.0\n",
      "Episode 975: Total Reward = -104.0\n",
      "Episode 976: Total Reward = -160.0\n",
      "Episode 977: Total Reward = -133.0\n",
      "Episode 978: Total Reward = -124.0\n",
      "Episode 979: Total Reward = -105.0\n",
      "Episode 980: Total Reward = -145.0\n",
      "Episode 981: Total Reward = -105.0\n",
      "Episode 982: Total Reward = -136.0\n",
      "Episode 983: Total Reward = -116.0\n",
      "Episode 984: Total Reward = -89.0\n",
      "Episode 985: Total Reward = -105.0\n",
      "Episode 986: Total Reward = -159.0\n",
      "Episode 987: Total Reward = -90.0\n",
      "Episode 988: Total Reward = -105.0\n",
      "Episode 989: Total Reward = -143.0\n",
      "Episode 990: Total Reward = -136.0\n",
      "Episode 991: Total Reward = -134.0\n",
      "Episode 992: Total Reward = -105.0\n",
      "Episode 993: Total Reward = -147.0\n",
      "Episode 994: Total Reward = -106.0\n",
      "Episode 995: Total Reward = -106.0\n",
      "Episode 996: Total Reward = -105.0\n",
      "Episode 997: Total Reward = -137.0\n",
      "Episode 998: Total Reward = -153.0\n",
      "Episode 999: Total Reward = -134.0\n",
      "Episode 1000: Total Reward = -105.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "v0_agent = SarsaAgent(gym.make(\"MountainCar-v0\"), mc_tile_encoding)\n",
    "\n",
    "rewards_historic = v0_agent.train(\n",
    "    nb_episodes=1000, alpha=0.1, gamma=0.99, epsilon=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UclLyzGSAmjK",
    "outputId": "cf6d82d4-480d-47d1-c291-9b47bbe233ac"
   },
   "outputs": [],
   "source": [
    "def test_policy(Q, num_episodes=10, render=False):\n",
    "    render = \"humane\" if render else None\n",
    "    env = gym.make(\"MountainCar-v0\", render_mode=None)\n",
    "    total_rewards = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()[0]\n",
    "        position, velocity = state\n",
    "        time_over = False\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not (done or time_over):\n",
    "\n",
    "            # Obtenir les tiles pour l'état actuel\n",
    "            state_tiles = tile_encoding(position, velocity)\n",
    "\n",
    "            # Choisir l'action qui maximise Q(s, a)\n",
    "            q_values = [\n",
    "                sum(Q.get((tile, action), 0) for tile in state_tiles)\n",
    "                for action in range(env.action_space.n)\n",
    "            ]\n",
    "            action = np.argmax(q_values)\n",
    "\n",
    "            # Exécuter l'action choisie\n",
    "            next_state, reward, done, time_over, _ = env.step(action)\n",
    "            position, velocity = next_state\n",
    "\n",
    "            total_reward += reward\n",
    "\n",
    "        total_rewards.append(total_reward)\n",
    "        print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "    env.close()\n",
    "    print(\n",
    "        f\"Average Total Reward over {num_episodes} episodes: {np.mean(total_rewards)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.54168844,  0.        ], dtype=float32), {})"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -89.0\n",
      "Episode 2: Total Reward = -140.0\n",
      "Episode 3: Total Reward = -106.0\n",
      "Episode 4: Total Reward = -105.0\n",
      "Episode 5: Total Reward = -93.0\n",
      "Episode 6: Total Reward = -105.0\n",
      "Episode 7: Total Reward = -106.0\n",
      "Episode 8: Total Reward = -147.0\n",
      "Episode 9: Total Reward = -105.0\n",
      "Episode 10: Total Reward = -105.0\n",
      "Average Total Reward over 10 episodes: -110.1\n"
     ]
    }
   ],
   "source": [
    "# Tester la politique optimale\n",
    "test_policy(Q, num_episodes=10, render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Experimentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
      "Action space: Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\n",
    "    \"MountainCar-v0\",\n",
    "    render_mode=\"human\",  # Cas discret\n",
    ")\n",
    "\n",
    "env.reset()\n",
    "print(f\"State space: {env.observation_space}\")\n",
    "print(f\"Action space: {env.action_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(array([-0.5598817 ,  0.00128113], dtype=float32), -1.0, False, False, {})\n",
      "-1.0\n",
      "1\n",
      "(array([-0.55732894,  0.00255272], dtype=float32), -1.0, False, False, {})\n",
      "-2.0\n",
      "2\n",
      "(array([-0.55352366,  0.00380526], dtype=float32), -1.0, False, False, {})\n",
      "-3.0\n",
      "3\n",
      "(array([-0.5484943,  0.0050294], dtype=float32), -1.0, False, False, {})\n",
      "-4.0\n",
      "4\n",
      "(array([-0.54227835,  0.00621594], dtype=float32), -1.0, False, False, {})\n",
      "-5.0\n",
      "5\n",
      "(array([-0.53492236,  0.00735597], dtype=float32), -1.0, False, False, {})\n",
      "-6.0\n",
      "6\n",
      "(array([-0.5264815 ,  0.00844088], dtype=float32), -1.0, False, False, {})\n",
      "-7.0\n",
      "7\n",
      "(array([-0.51701903,  0.0094625 ], dtype=float32), -1.0, False, False, {})\n",
      "-8.0\n",
      "8\n",
      "(array([-0.50660586,  0.01041315], dtype=float32), -1.0, False, False, {})\n",
      "-9.0\n",
      "9\n",
      "(array([-0.4953201 ,  0.01128576], dtype=float32), -1.0, False, False, {})\n",
      "-10.0\n",
      "10\n",
      "(array([-0.48324618,  0.01207392], dtype=float32), -1.0, False, False, {})\n",
      "-11.0\n",
      "11\n",
      "(array([-0.47047415,  0.01277202], dtype=float32), -1.0, False, False, {})\n",
      "-12.0\n",
      "12\n",
      "(array([-0.4570989 ,  0.01337527], dtype=float32), -1.0, False, False, {})\n",
      "-13.0\n",
      "13\n",
      "(array([-0.44321907,  0.01387982], dtype=float32), -1.0, False, False, {})\n",
      "-14.0\n",
      "14\n",
      "(array([-0.42893627,  0.0142828 ], dtype=float32), -1.0, False, False, {})\n",
      "-15.0\n",
      "15\n",
      "(array([-0.41435394,  0.01458233], dtype=float32), -1.0, False, False, {})\n",
      "-16.0\n",
      "16\n",
      "(array([-0.39957634,  0.01477759], dtype=float32), -1.0, False, False, {})\n",
      "-17.0\n",
      "17\n",
      "(array([-0.38470763,  0.01486873], dtype=float32), -1.0, False, False, {})\n",
      "-18.0\n",
      "18\n",
      "(array([-0.3698507 ,  0.01485693], dtype=float32), -1.0, False, False, {})\n",
      "-19.0\n",
      "19\n",
      "(array([-0.3551064 ,  0.01474427], dtype=float32), -1.0, False, False, {})\n",
      "-20.0\n",
      "20\n",
      "(array([-0.3405727 ,  0.01453371], dtype=float32), -1.0, False, False, {})\n",
      "-21.0\n",
      "21\n",
      "(array([-0.32634374,  0.01422896], dtype=float32), -1.0, False, False, {})\n",
      "-22.0\n",
      "22\n",
      "(array([-0.31250936,  0.01383439], dtype=float32), -1.0, False, False, {})\n",
      "-23.0\n",
      "23\n",
      "(array([-0.29915443,  0.01335493], dtype=float32), -1.0, False, False, {})\n",
      "-24.0\n",
      "24\n",
      "(array([-0.28635848,  0.01279595], dtype=float32), -1.0, False, False, {})\n",
      "-25.0\n",
      "25\n",
      "(array([-0.27419537,  0.0121631 ], dtype=float32), -1.0, False, False, {})\n",
      "-26.0\n",
      "26\n",
      "(array([-0.2627331 ,  0.01146228], dtype=float32), -1.0, False, False, {})\n",
      "-27.0\n",
      "27\n",
      "(array([-0.25203362,  0.01069947], dtype=float32), -1.0, False, False, {})\n",
      "-28.0\n",
      "28\n",
      "(array([-0.24215293,  0.00988068], dtype=float32), -1.0, False, False, {})\n",
      "-29.0\n",
      "29\n",
      "(array([-0.23314108,  0.00901185], dtype=float32), -1.0, False, False, {})\n",
      "-30.0\n",
      "30\n",
      "(array([-0.22504225,  0.00809882], dtype=float32), -1.0, False, False, {})\n",
      "-31.0\n",
      "31\n",
      "(array([-0.21789502,  0.00714725], dtype=float32), -1.0, False, False, {})\n",
      "-32.0\n",
      "32\n",
      "(array([-0.21173239,  0.00616263], dtype=float32), -1.0, False, False, {})\n",
      "-33.0\n",
      "33\n",
      "(array([-0.20658214,  0.00515024], dtype=float32), -1.0, False, False, {})\n",
      "-34.0\n",
      "34\n",
      "(array([-0.20246696,  0.00411518], dtype=float32), -1.0, False, False, {})\n",
      "-35.0\n",
      "35\n",
      "(array([-0.19940461,  0.00306234], dtype=float32), -1.0, False, False, {})\n",
      "-36.0\n",
      "36\n",
      "(array([-0.19740812,  0.00199649], dtype=float32), -1.0, False, False, {})\n",
      "-37.0\n",
      "37\n",
      "(array([-0.19648589,  0.00092223], dtype=float32), -1.0, False, False, {})\n",
      "-38.0\n",
      "38\n",
      "(array([-1.9664177e-01, -1.5587256e-04], dtype=float32), -1.0, False, False, {})\n",
      "-39.0\n",
      "39\n",
      "(array([-0.1978751 , -0.00123333], dtype=float32), -1.0, False, False, {})\n",
      "-40.0\n",
      "40\n",
      "(array([-0.20018072, -0.00230562], dtype=float32), -1.0, False, False, {})\n",
      "-41.0\n",
      "41\n",
      "(array([-0.20354892, -0.0033682 ], dtype=float32), -1.0, False, False, {})\n",
      "-42.0\n",
      "42\n",
      "(array([-0.20796531, -0.00441639], dtype=float32), -1.0, False, False, {})\n",
      "-43.0\n",
      "43\n",
      "(array([-0.21341072, -0.00544541], dtype=float32), -1.0, False, False, {})\n",
      "-44.0\n",
      "44\n",
      "(array([-0.21986103, -0.0064503 ], dtype=float32), -1.0, False, False, {})\n",
      "-45.0\n",
      "45\n",
      "(array([-0.22728695, -0.00742592], dtype=float32), -1.0, False, False, {})\n",
      "-46.0\n",
      "46\n",
      "(array([-0.23565388, -0.00836693], dtype=float32), -1.0, False, False, {})\n",
      "-47.0\n",
      "47\n",
      "(array([-0.24492165, -0.00926777], dtype=float32), -1.0, False, False, {})\n",
      "-48.0\n",
      "48\n",
      "(array([-0.2550444 , -0.01012275], dtype=float32), -1.0, False, False, {})\n",
      "-49.0\n",
      "49\n",
      "(array([-0.26597038, -0.01092597], dtype=float32), -1.0, False, False, {})\n",
      "-50.0\n",
      "50\n",
      "(array([-0.27764186, -0.01167148], dtype=float32), -1.0, False, False, {})\n",
      "-51.0\n",
      "51\n",
      "(array([-0.2899951 , -0.01235326], dtype=float32), -1.0, False, False, {})\n",
      "-52.0\n",
      "52\n",
      "(array([-0.3029605 , -0.01296536], dtype=float32), -1.0, False, False, {})\n",
      "-53.0\n",
      "53\n",
      "(array([-0.3164624 , -0.01350193], dtype=float32), -1.0, False, False, {})\n",
      "-54.0\n",
      "54\n",
      "(array([-0.33041978, -0.01395738], dtype=float32), -1.0, False, False, {})\n",
      "-55.0\n",
      "55\n",
      "(array([-0.34474626, -0.01432648], dtype=float32), -1.0, False, False, {})\n",
      "-56.0\n",
      "56\n",
      "(array([-0.35935068, -0.01460443], dtype=float32), -1.0, False, False, {})\n",
      "-57.0\n",
      "57\n",
      "(array([-0.37413773, -0.01478704], dtype=float32), -1.0, False, False, {})\n",
      "-58.0\n",
      "58\n",
      "(array([-0.38900855, -0.01487081], dtype=float32), -1.0, False, False, {})\n",
      "-59.0\n",
      "59\n",
      "(array([-0.40386158, -0.01485303], dtype=float32), -1.0, False, False, {})\n",
      "-60.0\n",
      "60\n",
      "(array([-0.41859347, -0.01473187], dtype=float32), -1.0, False, False, {})\n",
      "-61.0\n",
      "61\n",
      "(array([-0.4330999 , -0.01450645], dtype=float32), -1.0, False, False, {})\n",
      "-62.0\n",
      "62\n",
      "(array([-0.4472768 , -0.01417689], dtype=float32), -1.0, False, False, {})\n",
      "-63.0\n",
      "63\n",
      "(array([-0.4610211 , -0.01374431], dtype=float32), -1.0, False, False, {})\n",
      "-64.0\n",
      "64\n",
      "(array([-0.474232  , -0.01321089], dtype=float32), -1.0, False, False, {})\n",
      "-65.0\n",
      "65\n",
      "(array([-0.4868118 , -0.01257979], dtype=float32), -1.0, False, False, {})\n",
      "-66.0\n",
      "66\n",
      "(array([-0.49866694, -0.01185514], dtype=float32), -1.0, False, False, {})\n",
      "-67.0\n",
      "67\n",
      "(array([-0.5097089 , -0.01104195], dtype=float32), -1.0, False, False, {})\n",
      "-68.0\n",
      "68\n",
      "(array([-0.51985496, -0.01014609], dtype=float32), -1.0, False, False, {})\n",
      "-69.0\n",
      "69\n",
      "(array([-0.52902913, -0.00917417], dtype=float32), -1.0, False, False, {})\n",
      "-70.0\n",
      "70\n",
      "(array([-0.5371626 , -0.00813345], dtype=float32), -1.0, False, False, {})\n",
      "-71.0\n",
      "71\n",
      "(array([-0.54419434, -0.00703175], dtype=float32), -1.0, False, False, {})\n",
      "-72.0\n",
      "72\n",
      "(array([-0.5500717 , -0.00587738], dtype=float32), -1.0, False, False, {})\n",
      "-73.0\n",
      "73\n",
      "(array([-0.55475074, -0.00467904], dtype=float32), -1.0, False, False, {})\n",
      "-74.0\n",
      "74\n",
      "(array([-0.5581965 , -0.00344574], dtype=float32), -1.0, False, False, {})\n",
      "-75.0\n",
      "75\n",
      "(array([-0.5603832 , -0.00218672], dtype=float32), -1.0, False, False, {})\n",
      "-76.0\n",
      "76\n",
      "(array([-0.5612946, -0.0009114], dtype=float32), -1.0, False, False, {})\n",
      "-77.0\n",
      "77\n",
      "(array([-5.6092387e-01,  3.7071845e-04], dtype=float32), -1.0, False, False, {})\n",
      "-78.0\n",
      "78\n",
      "(array([-0.55927384,  0.00165007], dtype=float32), -1.0, False, False, {})\n",
      "-79.0\n",
      "79\n",
      "(array([-0.5563567 ,  0.00291712], dtype=float32), -1.0, False, False, {})\n",
      "-80.0\n",
      "80\n",
      "(array([-0.5521943 ,  0.00416241], dtype=float32), -1.0, False, False, {})\n",
      "-81.0\n",
      "81\n",
      "(array([-0.54681766,  0.00537662], dtype=float32), -1.0, False, False, {})\n",
      "-82.0\n",
      "82\n",
      "(array([-0.54026705,  0.00655062], dtype=float32), -1.0, False, False, {})\n",
      "-83.0\n",
      "83\n",
      "(array([-0.53259146,  0.00767558], dtype=float32), -1.0, False, False, {})\n",
      "-84.0\n",
      "84\n",
      "(array([-0.5238485 ,  0.00874302], dtype=float32), -1.0, False, False, {})\n",
      "-85.0\n",
      "85\n",
      "(array([-0.5141036 ,  0.00974489], dtype=float32), -1.0, False, False, {})\n",
      "-86.0\n",
      "86\n",
      "(array([-0.5034299 ,  0.01067368], dtype=float32), -1.0, False, False, {})\n",
      "-87.0\n",
      "87\n",
      "(array([-0.4919074 ,  0.01152251], dtype=float32), -1.0, False, False, {})\n",
      "-88.0\n",
      "88\n",
      "(array([-0.4796222 ,  0.01228518], dtype=float32), -1.0, False, False, {})\n",
      "-89.0\n",
      "89\n",
      "(array([-0.4666659 ,  0.01295631], dtype=float32), -1.0, False, False, {})\n",
      "-90.0\n",
      "90\n",
      "(array([-0.4531345 ,  0.01353139], dtype=float32), -1.0, False, False, {})\n",
      "-91.0\n",
      "91\n",
      "(array([-0.43912765,  0.01400683], dtype=float32), -1.0, False, False, {})\n",
      "-92.0\n",
      "92\n",
      "(array([-0.4247476 ,  0.01438006], dtype=float32), -1.0, False, False, {})\n",
      "-93.0\n",
      "93\n",
      "(array([-0.4100981,  0.0146495], dtype=float32), -1.0, False, False, {})\n",
      "-94.0\n",
      "94\n",
      "(array([-0.39528352,  0.01481459], dtype=float32), -1.0, False, False, {})\n",
      "-95.0\n",
      "95\n",
      "(array([-0.3804077 ,  0.01487582], dtype=float32), -1.0, False, False, {})\n",
      "-96.0\n",
      "96\n",
      "(array([-0.36557308,  0.01483462], dtype=float32), -1.0, False, False, {})\n",
      "-97.0\n",
      "97\n",
      "(array([-0.35087976,  0.01469332], dtype=float32), -1.0, False, False, {})\n",
      "-98.0\n",
      "98\n",
      "(array([-0.33642462,  0.01445512], dtype=float32), -1.0, False, False, {})\n",
      "-99.0\n",
      "99\n",
      "(array([-0.3223007 ,  0.01412393], dtype=float32), -1.0, False, False, {})\n",
      "-100.0\n",
      "100\n",
      "(array([-0.3085964,  0.0137043], dtype=float32), -1.0, False, False, {})\n",
      "-101.0\n",
      "101\n",
      "(array([-0.2953951 ,  0.01320129], dtype=float32), -1.0, False, False, {})\n",
      "-102.0\n",
      "102\n",
      "(array([-0.28277475,  0.01262036], dtype=float32), -1.0, False, False, {})\n",
      "-103.0\n",
      "103\n",
      "(array([-0.27080747,  0.01196726], dtype=float32), -1.0, False, False, {})\n",
      "-104.0\n",
      "104\n",
      "(array([-0.25955957,  0.0112479 ], dtype=float32), -1.0, False, False, {})\n",
      "-105.0\n",
      "105\n",
      "(array([-0.24909127,  0.0104683 ], dtype=float32), -1.0, False, False, {})\n",
      "-106.0\n",
      "106\n",
      "(array([-0.23945683,  0.00963444], dtype=float32), -1.0, False, False, {})\n",
      "-107.0\n",
      "107\n",
      "(array([-0.23070459,  0.00875224], dtype=float32), -1.0, False, False, {})\n",
      "-108.0\n",
      "108\n",
      "(array([-0.2228771 ,  0.00782749], dtype=float32), -1.0, False, False, {})\n",
      "-109.0\n",
      "109\n",
      "(array([-0.21601129,  0.00686582], dtype=float32), -1.0, False, False, {})\n",
      "-110.0\n",
      "110\n",
      "(array([-0.21013865,  0.00587264], dtype=float32), -1.0, False, False, {})\n",
      "-111.0\n",
      "111\n",
      "(array([-0.20528547,  0.00485318], dtype=float32), -1.0, False, False, {})\n",
      "-112.0\n",
      "112\n",
      "(array([-0.20147298,  0.00381248], dtype=float32), -1.0, False, False, {})\n",
      "-113.0\n",
      "113\n",
      "(array([-0.19871758,  0.0027554 ], dtype=float32), -1.0, False, False, {})\n",
      "-114.0\n",
      "114\n",
      "(array([-0.19703093,  0.00168665], dtype=float32), -1.0, False, False, {})\n",
      "-115.0\n",
      "115\n",
      "(array([-0.19642012,  0.00061082], dtype=float32), -1.0, False, False, {})\n",
      "-116.0\n",
      "116\n",
      "(array([-0.19688769, -0.00046756], dtype=float32), -1.0, False, False, {})\n",
      "-117.0\n",
      "117\n",
      "(array([-0.19843167, -0.00154399], dtype=float32), -1.0, False, False, {})\n",
      "-118.0\n",
      "118\n",
      "(array([-0.20104563, -0.00261395], dtype=float32), -1.0, False, False, {})\n",
      "-119.0\n",
      "119\n",
      "(array([-0.20471849, -0.00367285], dtype=float32), -1.0, False, False, {})\n",
      "-120.0\n",
      "120\n",
      "(array([-0.20943448, -0.004716  ], dtype=float32), -1.0, False, False, {})\n",
      "-121.0\n",
      "121\n",
      "(array([-0.21517305, -0.00573857], dtype=float32), -1.0, False, False, {})\n",
      "-122.0\n",
      "122\n",
      "(array([-0.22190858, -0.00673554], dtype=float32), -1.0, False, False, {})\n",
      "-123.0\n",
      "123\n",
      "(array([-0.2296103 , -0.00770171], dtype=float32), -1.0, False, False, {})\n",
      "-124.0\n",
      "124\n",
      "(array([-0.23824197, -0.00863168], dtype=float32), -1.0, False, False, {})\n",
      "-125.0\n",
      "125\n",
      "(array([-0.24776183, -0.00951986], dtype=float32), -1.0, False, False, {})\n",
      "-126.0\n",
      "126\n",
      "(array([-0.25812232, -0.01036049], dtype=float32), -1.0, False, False, {})\n",
      "-127.0\n",
      "127\n",
      "(array([-0.26926997, -0.01114765], dtype=float32), -1.0, False, False, {})\n",
      "-128.0\n",
      "128\n",
      "(array([-0.28114533, -0.01187535], dtype=float32), -1.0, False, False, {})\n",
      "-129.0\n",
      "129\n",
      "(array([-0.29368293, -0.01253761], dtype=float32), -1.0, False, False, {})\n",
      "-130.0\n",
      "130\n",
      "(array([-0.3068114 , -0.01312846], dtype=float32), -1.0, False, False, {})\n",
      "-131.0\n",
      "131\n",
      "(array([-0.32045352, -0.01364215], dtype=float32), -1.0, False, False, {})\n",
      "-132.0\n",
      "132\n",
      "(array([-0.3345267 , -0.01407316], dtype=float32), -1.0, False, False, {})\n",
      "-133.0\n",
      "133\n",
      "(array([-0.34894308, -0.01441638], dtype=float32), -1.0, False, False, {})\n",
      "-134.0\n",
      "134\n",
      "(array([-0.36361024, -0.01466717], dtype=float32), -1.0, False, False, {})\n",
      "-135.0\n",
      "135\n",
      "(array([-0.3784318 , -0.01482154], dtype=float32), -1.0, False, False, {})\n",
      "-136.0\n",
      "136\n",
      "(array([-0.39330798, -0.01487621], dtype=float32), -1.0, False, False, {})\n",
      "-137.0\n",
      "137\n",
      "(array([-0.4081367 , -0.01482869], dtype=float32), -1.0, False, False, {})\n",
      "-138.0\n",
      "138\n",
      "(array([-0.42281413, -0.01467745], dtype=float32), -1.0, False, False, {})\n",
      "-139.0\n",
      "139\n",
      "(array([-0.437236  , -0.01442187], dtype=float32), -1.0, False, False, {})\n",
      "-140.0\n",
      "140\n",
      "(array([-0.45129836, -0.01406237], dtype=float32), -1.0, False, False, {})\n",
      "-141.0\n",
      "141\n",
      "(array([-0.46489874, -0.01360038], dtype=float32), -1.0, False, False, {})\n",
      "-142.0\n",
      "142\n",
      "(array([-0.4779371 , -0.01303835], dtype=float32), -1.0, False, False, {})\n",
      "-143.0\n",
      "143\n",
      "(array([-0.49031684, -0.01237975], dtype=float32), -1.0, False, False, {})\n",
      "-144.0\n",
      "144\n",
      "(array([-0.5019458 , -0.01162895], dtype=float32), -1.0, False, False, {})\n",
      "-145.0\n",
      "145\n",
      "(array([-0.51273704, -0.01079123], dtype=float32), -1.0, False, False, {})\n",
      "-146.0\n",
      "146\n",
      "(array([-0.5226097 , -0.00987268], dtype=float32), -1.0, False, False, {})\n",
      "-147.0\n",
      "147\n",
      "(array([-0.5314898, -0.0088801], dtype=float32), -1.0, False, False, {})\n",
      "-148.0\n",
      "148\n",
      "(array([-0.5393107 , -0.00782092], dtype=float32), -1.0, False, False, {})\n",
      "-149.0\n",
      "149\n",
      "(array([-0.54601383, -0.00670312], dtype=float32), -1.0, False, False, {})\n",
      "-150.0\n",
      "150\n",
      "(array([-0.55154896, -0.00553514], dtype=float32), -1.0, False, False, {})\n",
      "-151.0\n",
      "151\n",
      "(array([-0.55587476, -0.00432576], dtype=float32), -1.0, False, False, {})\n",
      "-152.0\n",
      "152\n",
      "(array([-0.5589588 , -0.00308406], dtype=float32), -1.0, False, False, {})\n",
      "-153.0\n",
      "153\n",
      "(array([-0.56077814, -0.00181936], dtype=float32), -1.0, False, False, {})\n",
      "-154.0\n",
      "154\n",
      "(array([-5.6131923e-01, -5.4109422e-04], dtype=float32), -1.0, False, False, {})\n",
      "-155.0\n",
      "155\n",
      "(array([-0.56057805,  0.00074121], dtype=float32), -1.0, False, False, {})\n",
      "-156.0\n",
      "156\n",
      "(array([-0.5585601 ,  0.00201798], dtype=float32), -1.0, False, False, {})\n",
      "-157.0\n",
      "157\n",
      "(array([-0.5552804 ,  0.00327971], dtype=float32), -1.0, False, False, {})\n",
      "-158.0\n",
      "158\n",
      "(array([-0.55076337,  0.00451697], dtype=float32), -1.0, False, False, {})\n",
      "-159.0\n",
      "159\n",
      "(array([-0.54504293,  0.00572047], dtype=float32), -1.0, False, False, {})\n",
      "-160.0\n",
      "160\n",
      "(array([-0.53816175,  0.0068812 ], dtype=float32), -1.0, False, False, {})\n",
      "-161.0\n",
      "161\n",
      "(array([-0.53017133,  0.00799038], dtype=float32), -1.0, False, False, {})\n",
      "-162.0\n",
      "162\n",
      "(array([-0.5211317 ,  0.00903967], dtype=float32), -1.0, False, False, {})\n",
      "-163.0\n",
      "163\n",
      "(array([-0.5111105 ,  0.01002117], dtype=float32), -1.0, False, False, {})\n",
      "-164.0\n",
      "164\n",
      "(array([-0.500183  ,  0.01092753], dtype=float32), -1.0, False, False, {})\n",
      "-165.0\n",
      "165\n",
      "(array([-0.48843092,  0.01175206], dtype=float32), -1.0, False, False, {})\n",
      "-166.0\n",
      "166\n",
      "(array([-0.47594213,  0.01248879], dtype=float32), -1.0, False, False, {})\n",
      "-167.0\n",
      "167\n",
      "(array([-0.46280956,  0.01313258], dtype=float32), -1.0, False, False, {})\n",
      "-168.0\n",
      "168\n",
      "(array([-0.44913036,  0.01367918], dtype=float32), -1.0, False, False, {})\n",
      "-169.0\n",
      "169\n",
      "(array([-0.43500507,  0.0141253 ], dtype=float32), -1.0, False, False, {})\n",
      "-170.0\n",
      "170\n",
      "(array([-0.42053643,  0.01446864], dtype=float32), -1.0, False, False, {})\n",
      "-171.0\n",
      "171\n",
      "(array([-0.40582848,  0.01470793], dtype=float32), -1.0, False, False, {})\n",
      "-172.0\n",
      "172\n",
      "(array([-0.39098558,  0.01484292], dtype=float32), -1.0, False, False, {})\n",
      "-173.0\n",
      "173\n",
      "(array([-0.3761112 ,  0.01487435], dtype=float32), -1.0, False, False, {})\n",
      "-174.0\n",
      "174\n",
      "(array([-0.3613073 ,  0.01480393], dtype=float32), -1.0, False, False, {})\n",
      "-175.0\n",
      "175\n",
      "(array([-0.346673  ,  0.01463427], dtype=float32), -1.0, False, False, {})\n",
      "-176.0\n",
      "176\n",
      "(array([-0.33230424,  0.01436876], dtype=float32), -1.0, False, False, {})\n",
      "-177.0\n",
      "177\n",
      "(array([-0.31829274,  0.01401152], dtype=float32), -1.0, False, False, {})\n",
      "-178.0\n",
      "178\n",
      "(array([-0.3047255 ,  0.01356725], dtype=float32), -1.0, False, False, {})\n",
      "-179.0\n",
      "179\n",
      "(array([-0.29168436,  0.01304114], dtype=float32), -1.0, False, False, {})\n",
      "-180.0\n",
      "180\n",
      "(array([-0.27924562,  0.01243875], dtype=float32), -1.0, False, False, {})\n",
      "-181.0\n",
      "181\n",
      "(array([-0.26747972,  0.01176588], dtype=float32), -1.0, False, False, {})\n",
      "-182.0\n",
      "182\n",
      "(array([-0.25645122,  0.01102849], dtype=float32), -1.0, False, False, {})\n",
      "-183.0\n",
      "183\n",
      "(array([-0.24621864,  0.01023259], dtype=float32), -1.0, False, False, {})\n",
      "-184.0\n",
      "184\n",
      "(array([-0.23683448,  0.00938416], dtype=float32), -1.0, False, False, {})\n",
      "-185.0\n",
      "185\n",
      "(array([-0.22834541,  0.00848907], dtype=float32), -1.0, False, False, {})\n",
      "-186.0\n",
      "186\n",
      "(array([-0.22079232,  0.00755308], dtype=float32), -1.0, False, False, {})\n",
      "-187.0\n",
      "187\n",
      "(array([-0.21421057,  0.00658175], dtype=float32), -1.0, False, False, {})\n",
      "-188.0\n",
      "188\n",
      "(array([-0.20863011,  0.00558045], dtype=float32), -1.0, False, False, {})\n",
      "-189.0\n",
      "189\n",
      "(array([-0.20407577,  0.00455434], dtype=float32), -1.0, False, False, {})\n",
      "-190.0\n",
      "190\n",
      "(array([-0.20056735,  0.00350842], dtype=float32), -1.0, False, False, {})\n",
      "-191.0\n",
      "191\n",
      "(array([-0.19811986,  0.00244749], dtype=float32), -1.0, False, False, {})\n",
      "-192.0\n",
      "192\n",
      "(array([-0.19674365,  0.00137622], dtype=float32), -1.0, False, False, {})\n",
      "-193.0\n",
      "193\n",
      "(array([-0.19644447,  0.00029919], dtype=float32), -1.0, False, False, {})\n",
      "-194.0\n",
      "194\n",
      "(array([-0.19722356, -0.00077909], dtype=float32), -1.0, False, False, {})\n",
      "-195.0\n",
      "195\n",
      "(array([-0.19907768, -0.00185412], dtype=float32), -1.0, False, False, {})\n",
      "-196.0\n",
      "196\n",
      "(array([-0.20199902, -0.00292135], dtype=float32), -1.0, False, False, {})\n",
      "-197.0\n",
      "197\n",
      "(array([-0.20597522, -0.00397619], dtype=float32), -1.0, False, False, {})\n",
      "-198.0\n",
      "198\n",
      "(array([-0.21098912, -0.00501389], dtype=float32), -1.0, False, False, {})\n",
      "-199.0\n",
      "199\n",
      "(array([-0.2170187 , -0.00602958], dtype=float32), -1.0, False, True, {})\n",
      "-200.0\n",
      "200\n",
      "(array([-0.22403689, -0.00701819], dtype=float32), -1.0, False, True, {})\n",
      "-201.0\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(201):\n",
    "    print(i)\n",
    "    a = env.step(2)\n",
    "    sum += a[1]\n",
    "    print(a)\n",
    "    print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-115.0"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruedaPcEuf4N"
   },
   "source": [
    "### Code Pierre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1toDudAwuUiX"
   },
   "outputs": [],
   "source": [
    "def on_policy_monte_carlo(\n",
    "    env,\n",
    "    nb_states,\n",
    "    nb_actions,\n",
    "    encode_fct,\n",
    "    nb_episodes=20000,\n",
    "    gamma=1,\n",
    "    epsilon=0.1,\n",
    "    use_glei=False,\n",
    "    decay_rate=0.2,\n",
    "    min_epsilon=0.05,\n",
    "):\n",
    "    \"\"\"\n",
    "    This algorithm goal is to find the optimal policy in a episodic environement with reasonable number of states and actions\n",
    "    Convergence guaranteed in this paper: https://sites.ualberta.ca/~szepesva/papers/sarsa98.ps.pdf\n",
    "\n",
    "    Repeat for the given number of episodes:\n",
    "        Simulate an episode with the given policy\n",
    "        Compute the accumulated rewards with discount factor (gamma): G\n",
    "        For every visited q(s, a) in the current episode:\n",
    "            If first visit of (s, a) is at iteration t:\n",
    "                acc(s, a) += Gt\n",
    "                count(s, a) += 1\n",
    "                q(s, a) = acc(s, a) / count(s, a)\n",
    "            For every state in the current episode:\n",
    "                update policy(s, a) with an epsilon greedy strategy or GLEI strategy\n",
    "\n",
    "    Args:\n",
    "        - env (gymnasium.Env): a gymnasium environment\n",
    "        - nb_states (int): the number of states for the given env\n",
    "        - nb_actions (int): the number of actions for the given env\n",
    "        - encode_fct (callable): the function to encode our state.\n",
    "        - nb_episodes (int): number of episodes simulated for learning\n",
    "        - gamma (float): discount factor for updating states values\n",
    "        - epsilon (float): initial exploration factor, in [0, 1], if use_gley = True, represent the starting epsilon\n",
    "        - use_glei (bool): if True, use GLEI policy (decaying epsilon across episodes); if False, use simple epsilon-greedy\n",
    "        - decay_rate (float): Every time num_episode > nb_episode * (decay_rate *i) then epsilon = epsilon * (1 - decay_rate) * i. Where i is the number of time we decayed epsilon\n",
    "        - min_epsilon (float): the minimum decayed epsilon when using a GLEI policy\n",
    "\n",
    "    Returns:\n",
    "        - policy (numpy.array): the learnt policy\n",
    "        - q (numpy.array): the Q-values\n",
    "        - rewards_historic (list): the historic of rewards during training\n",
    "    \"\"\"\n",
    "    # Initialize algorithm variables\n",
    "    q = np.zeros(\n",
    "        shape=(nb_states, nb_actions)\n",
    "    )  # (state, action) values through every episodes generated\n",
    "    count = np.zeros(\n",
    "        shape=(nb_states, nb_actions)\n",
    "    )  # Counting each (s, a) events through every episodes generated\n",
    "    acc = np.zeros(\n",
    "        shape=(nb_states, nb_actions)\n",
    "    )  # (state, action) cumulated values through every episodes generated\n",
    "    policy = np.full(\n",
    "        shape=(nb_states, nb_actions), fill_value=1 / nb_actions\n",
    "    )  # Actions probabilities for each state. Initialized as a uniform policy\n",
    "    rewards_historic = []\n",
    "    count_decay = 1  # Decay rate factor\n",
    "\n",
    "    for num_episode in range(nb_episodes):\n",
    "        # print(f\"Computing ep {num_episode}\")\n",
    "\n",
    "        # Initialize environment\n",
    "        game_state = env.reset()[\n",
    "            0\n",
    "        ]  # A tuple (player score, opponent score, ace (1) or not (0))\n",
    "        terminated = False\n",
    "        G = np.empty((0, 1))  # Cumulated rewards of the current episode\n",
    "        moves_historic = np.empty(\n",
    "            (0, 2), dtype=int\n",
    "        )  # Historic of (state, action) of the current episode\n",
    "\n",
    "        # Step 1: Simulate an episode\n",
    "        while not terminated:\n",
    "            # Draw an action according to the current policy\n",
    "            state_index = encode_fct(game_state)\n",
    "            action = draw(policy, state_index)\n",
    "\n",
    "            # Update environment with the chosen action\n",
    "            env_state = env.step(action)\n",
    "            game_state, G, terminated = (\n",
    "                env_state[0],\n",
    "                np.append(G, env_state[1]),\n",
    "                env_state[2],\n",
    "            )\n",
    "\n",
    "            # Update current historic if current (state, action) was not visited yet\n",
    "            moves_historic = np.append(moves_historic, [[state_index, action]], axis=0)\n",
    "\n",
    "        # Update rewards_historic with the total reward of the episode\n",
    "        rewards_historic.append(np.sum(G))\n",
    "\n",
    "        # Step 2: Compute G, the cumulative rewards for each state\n",
    "        gamma_powers = gamma ** np.arange(len(G))\n",
    "        for i in range(len(G) - 1):\n",
    "            G[i] = np.sum(G[i:] * gamma_powers[: len(G[i:])])\n",
    "\n",
    "        # Step 3: For every (s, a) visited: Update q(s, a)\n",
    "        # Extracting first visit for every (s, a)\n",
    "        first_visit_states_action, first_visit_indices = np.unique(\n",
    "            moves_historic, axis=0, return_index=True\n",
    "        )\n",
    "        first_visit_indices = np.sort(first_visit_indices)\n",
    "\n",
    "        # Extract relevant states, actions, and rewards for first visits\n",
    "        states = moves_historic[first_visit_indices, 0]\n",
    "        actions = moves_historic[first_visit_indices, 1]\n",
    "        rewards = G[first_visit_indices]\n",
    "\n",
    "        # Update acc, count, and q arrays\n",
    "        np.add.at(acc, (states, actions), rewards)  # Accumulate rewards\n",
    "        np.add.at(count, (states, actions), 1)  # Increment count\n",
    "        q = np.divide(acc, count, where=(count != 0), out=np.zeros_like(acc))\n",
    "\n",
    "        # Step 4: Update policy with the current Q-values\n",
    "        # Update epsilon if we use GLEI policy\n",
    "        if (use_glei) & (num_episode > (decay_rate * count_decay) * nb_episodes):\n",
    "            epsilon = max(epsilon * (1 - (decay_rate * count_decay)), min_epsilon)\n",
    "            count_decay += 1\n",
    "        policy = update_eps_greedy_policy(epsilon=epsilon, q=q)\n",
    "\n",
    "    if use_glei:\n",
    "        print(f\"Final epsilon: {epsilon}\")\n",
    "    return policy, q, rewards_historic"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mountain-car-dUPDKyLO-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
